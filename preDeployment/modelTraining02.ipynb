{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hezobBLorFRR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6ada8777-531f-4e98-e3cc-909e20df4400",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601168420,
     "user_tz": -180,
     "elapsed": 37790,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUDA GPUs available: 1; using: NVIDIA A100-SXM4-40GB\n",
      "Cloning into 'rapidsai-csp-utils'...\n",
      "remote: Enumerating objects: 603, done.\u001B[K\n",
      "remote: Counting objects: 100% (169/169), done.\u001B[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001B[K\n",
      "remote: Total 603 (delta 131), reused 82 (delta 82), pack-reused 434 (from 3)\u001B[K\n",
      "Receiving objects: 100% (603/603), 199.38 KiB | 2.59 MiB/s, done.\n",
      "Resolving deltas: 100% (305/305), done.\n",
      "Installing RAPIDS remaining 25.08 libraries\n",
      "Using Python 3.12.11 environment at: /usr\n",
      "Resolved 177 packages in 2.93s\n",
      "Prepared 54 packages in 30.94s\n",
      "Uninstalled 32 packages in 947ms\n",
      "Installed 54 packages in 110ms\n",
      " + arrow==1.3.0\n",
      " - bokeh==3.7.3\n",
      " + bokeh==3.6.3\n",
      " + cucim-cu12==25.8.0\n",
      " + cuda-bindings==12.9.2\n",
      " + cuda-pathfinder==1.2.1\n",
      " - cuda-python==12.6.2.post1\n",
      " + cuda-python==12.9.2\n",
      " - cudf-cu12==25.6.0 (from https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl)\n",
      " + cudf-cu12==25.8.0\n",
      " + cugraph-cu12==25.8.0\n",
      " - cuml-cu12==25.6.0\n",
      " + cuml-cu12==25.8.0\n",
      " - cuvs-cu12==25.6.1\n",
      " + cuvs-cu12==25.8.0\n",
      " + cuxfilter-cu12==25.8.0\n",
      " - dask==2025.5.0\n",
      " + dask==2025.7.0\n",
      " - dask-cuda==25.6.0\n",
      " + dask-cuda==25.8.0\n",
      " - dask-cudf-cu12==25.6.0\n",
      " + dask-cudf-cu12==25.8.0\n",
      " + datashader==0.18.2\n",
      " - distributed==2025.5.0\n",
      " + distributed==2025.7.0\n",
      " - distributed-ucxx-cu12==0.44.0\n",
      " + distributed-ucxx-cu12==0.45.1\n",
      " + fqdn==1.5.1\n",
      " - holoviews==1.21.0\n",
      " + holoviews==1.20.2\n",
      " + isoduration==20.11.0\n",
      " - jupyter-client==6.1.12\n",
      " + jupyter-client==8.6.3\n",
      " + jupyter-events==0.12.0\n",
      " - jupyter-server==1.16.0\n",
      " + jupyter-server==2.17.0\n",
      " + jupyter-server-proxy==4.4.0\n",
      " + jupyter-server-terminals==0.5.3\n",
      " + lark==1.2.2\n",
      " - libcudf-cu12==25.6.0 (from https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.6.0-py3-none-manylinux_2_28_x86_64.whl)\n",
      " + libcudf-cu12==25.8.0\n",
      " - libcugraph-cu12==25.6.0\n",
      " + libcugraph-cu12==25.8.0\n",
      " - libcuml-cu12==25.6.0\n",
      " + libcuml-cu12==25.8.0\n",
      " - libcuvs-cu12==25.6.1\n",
      " + libcuvs-cu12==25.8.0\n",
      " - libkvikio-cu12==25.6.0\n",
      " + libkvikio-cu12==25.8.0\n",
      " - libraft-cu12==25.6.0\n",
      " + libraft-cu12==25.8.0\n",
      " - librmm-cu12==25.6.0\n",
      " + librmm-cu12==25.8.0\n",
      " - libucxx-cu12==0.44.0\n",
      " + libucxx-cu12==0.45.1\n",
      " - numba-cuda==0.11.0\n",
      " + numba-cuda==0.14.1\n",
      " + nvidia-cuda-cccl-cu12==12.9.27\n",
      " - nx-cugraph-cu12==25.6.0 (from https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.6.0-py3-none-any.whl)\n",
      " + nx-cugraph-cu12==25.8.0\n",
      " + pyct==0.5.0\n",
      " - pylibcudf-cu12==25.6.0 (from https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl)\n",
      " + pylibcudf-cu12==25.8.0\n",
      " - pylibcugraph-cu12==25.6.0\n",
      " + pylibcugraph-cu12==25.8.0\n",
      " - pylibraft-cu12==25.6.0\n",
      " + pylibraft-cu12==25.8.0\n",
      " + python-json-logger==3.3.0\n",
      " - raft-dask-cu12==25.6.0\n",
      " + raft-dask-cu12==25.8.0\n",
      " - rapids-dask-dependency==25.6.0\n",
      " + rapids-dask-dependency==25.8.0\n",
      " + rfc3339-validator==0.1.4\n",
      " + rfc3986-validator==0.1.1\n",
      " + rfc3987-syntax==1.1.0\n",
      " - rmm-cu12==25.6.0\n",
      " + rmm-cu12==25.8.0\n",
      " - shapely==2.1.1\n",
      " + shapely==2.0.7\n",
      " + simpervisor==1.0.0\n",
      " + types-python-dateutil==2.9.0.20250822\n",
      " - ucx-py-cu12==0.44.0\n",
      " + ucx-py-cu12==0.45.0\n",
      " - ucxx-cu12==0.44.0\n",
      " + ucxx-cu12==0.45.1\n",
      " + uri-template==1.3.0\n",
      "\n",
      "        ***********************************************************************\n",
      "        The pip install of RAPIDS is complete.\n",
      "\n",
      "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
      "\n",
      "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
      "\n",
      "        Troubleshooting:\n",
      "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files.\n",
      "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
      "        ***********************************************************************\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 0) Environment checks\n",
    "# ----------------------\n",
    "\n",
    "def _check_gpu():\n",
    "    try:\n",
    "        import cupy as cp  # noqa\n",
    "        n = cp.cuda.runtime.getDeviceCount()\n",
    "        assert n > 0, \"No CUDA GPU visible. In Colab: Runtime -> Change runtime type -> GPU\"\n",
    "        dev = cp.cuda.runtime.getDevice()\n",
    "        props = cp.cuda.runtime.getDeviceProperties(dev)\n",
    "        name = props.get('name', b'').decode('utf-8', errors='ignore')\n",
    "        print(f\"CUDA GPUs available: {n}; using: {name}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] GPU check failed:\", e)\n",
    "        print(\"If you're on Colab/Kaggle, enable a GPU first.\")\n",
    "\n",
    "_check_gpu()\n",
    "\n",
    "# --------------------------------\n",
    "# 1) (Optional) Quick RAPIDS install\n",
    "# --------------------------------\n",
    "# If cuML isn't installed yet, uncomment ONE of the blocks below.\n",
    "\n",
    "# A) Colab-friendly helper (conda under-the-hood)\n",
    "!git clone https://github.com/rapidsai-community/rapidsai-csp-utils.git\n",
    "!python rapidsai-csp-utils/colab/pip-install.py  # installs RAPIDS stable incl. cuML\n",
    "\n",
    "# B) Pip wheels (CUDA 12.x). Works on many environments with CUDA 12.*\n",
    "# !pip -q install --extra-index-url=https://pypi.nvidia.com cupy-cuda12x cudf-cu12 cuml-cu12"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os, sys, time, json, math, pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# GPU + metrics imports\n",
    "import cupy as cp\n",
    "import cudf\n",
    "from cuml.svm import SVC\n",
    "from cuml.linear_model import LogisticRegression\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.neighbors import KNeighborsClassifier\n",
    "from cuml.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix\n",
    ")"
   ],
   "metadata": {
    "id": "sJT6JeVasSYc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601178815,
     "user_tz": -180,
     "elapsed": 6745,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 3) Load your saved features\n",
    "# ---------------------------\n",
    "# First, you need to upload your 'features_scaled' directory to Colab\n",
    "# or mount your Google Drive where the files are located.\n",
    "\n",
    "# Example if you uploaded a zip file:\n",
    "# !unzip features_scaled.zip\n",
    "\n",
    "DATA_DIR = Path('./features_raw')  # change to ./features_raw if you prefer\n",
    "assert (DATA_DIR / 'train.npz').exists(), f\"Can't find {DATA_DIR/'train.npz'} â€” check your paths.\"\n",
    "\n",
    "train = np.load(DATA_DIR / 'train.npz', allow_pickle=False)\n",
    "val   = np.load(DATA_DIR / 'val.npz',   allow_pickle=False)\n",
    "test  = np.load(DATA_DIR / 'test.npz',  allow_pickle=False)\n",
    "\n",
    "X_tr = train['X'].astype(np.float32)\n",
    "Y_tr = train['y'].astype(np.int32)\n",
    "classes = train['classes'].tolist()\n",
    "\n",
    "X_va = val['X'].astype(np.float32)\n",
    "Y_va = val['y'].astype(np.int32)\n",
    "\n",
    "X_te = test['X'].astype(np.float32)\n",
    "Y_te = test['y'].astype(np.int32)\n",
    "\n",
    "# Drop any -1 labels (just in case some class didn't appear in train)\n",
    "keep_va = Y_va >= 0\n",
    "keep_te = Y_te >= 0\n",
    "X_va, Y_va = X_va[keep_va], Y_va[keep_va]\n",
    "X_te, Y_te = X_te[keep_te], Y_te[keep_te]\n",
    "\n",
    "print(\"Shapes (scaled):\", X_tr.shape, X_va.shape, X_te.shape)\n",
    "print(\"Classes:\", classes)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dz4XKVyQsUSd",
    "outputId": "0e6fe137-240a-45a4-b0c0-3c1ac64b2aa4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756602567008,
     "user_tz": -180,
     "elapsed": 646,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shapes (scaled): (17714, 1584) (2023, 1584) (2394, 1584)\n",
      "Classes: ['angry', 'happy', 'neutral', 'sad']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 4) Move to GPU (CuPy arrays)\n",
    "# ---------------------------\n",
    "Xtr = cp.asarray(X_tr)\n",
    "Ytr = cp.asarray(Y_tr)\n",
    "Xva = cp.asarray(X_va)\n",
    "Yva = cp.asarray(Y_va)\n",
    "Xte = cp.asarray(X_te)\n",
    "Yte = cp.asarray(Y_te)\n",
    "\n",
    "n_classes = int(cp.asnumpy(Ytr.max()) + 1)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Class imbalance handling\n",
    "# ---------------------------\n",
    "# We'll compute inverse-frequency sample weights on the TRAIN set and try to pass them\n",
    "# to models that support it. If a model doesn't support sample_weight, we'll skip it.\n",
    "\n",
    "vals, counts = cp.unique(Ytr, return_counts=True)\n",
    "class_freq = cp.zeros(n_classes, dtype=cp.float32)\n",
    "class_freq[vals] = counts\n",
    "class_weights = (len(Ytr) / (n_classes * class_freq)).astype(cp.float32)\n",
    "train_weights = class_weights[Ytr]\n",
    "\n",
    "print(\"Class counts:\", dict(zip(cp.asnumpy(vals).tolist(), cp.asnumpy(counts).tolist())))\n",
    "print(\"Class weights:\", cp.asnumpy(class_weights))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pd6NV6DOsVoQ",
    "outputId": "9cdd9a87-f453-4c29-9953-d0e2ce526f37",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756602585649,
     "user_tz": -180,
     "elapsed": 32,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class counts: {0: 4485, 1: 4485, 2: 4260, 3: 4484}\n",
      "Class weights: [0.98740244 0.98740244 1.039554   0.9876227 ]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 6) Utilities: training, evaluation & plotting\n",
    "\n",
    "OUT = Path(\"./results\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _to_cpu(x):\n",
    "    return cp.asnumpy(x) if isinstance(x, cp.ndarray) else x\n",
    "\n",
    "\n",
    "def evaluate(name: str, model, Xtr, Ytr, Xva, Yva, Xte, Yte, sample_weight=None):\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        if sample_weight is not None:\n",
    "            model.fit(Xtr, Ytr, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(Xtr, Ytr)\n",
    "    except TypeError:\n",
    "        # model doesn't accept sample_weight\n",
    "        print(f\"   [Info] Model {name} does not support sample_weight. Training without it.\")\n",
    "        model.fit(Xtr, Ytr)\n",
    "    tr_time = time.time() - t0\n",
    "\n",
    "    # Predictions\n",
    "    P_va = model.predict(Xva)\n",
    "    P_te = model.predict(Xte)\n",
    "\n",
    "    # Metrics on CPU for convenience\n",
    "    yv = _to_cpu(Yva); yt = _to_cpu(Yte)\n",
    "    pv = _to_cpu(P_va); pt = _to_cpu(P_te)\n",
    "\n",
    "    acc_va = accuracy_score(yv, pv)\n",
    "    f1m_va = f1_score(yv, pv, average='macro')\n",
    "    acc_te = accuracy_score(yt, pt)\n",
    "    f1m_te = f1_score(yt, pt, average='macro')\n",
    "\n",
    "    print(f\"{name}: val acc={acc_va:.4f} f1_macro={f1m_va:.4f} | test acc={acc_te:.4f} f1_macro={f1m_te:.4f} (fit {tr_time:.2f}s)\")\n",
    "\n",
    "    # Save confusion matrix on test\n",
    "    cm = confusion_matrix(yt, pt, labels=list(range(n_classes)))\n",
    "    fig = plt.figure(figsize=(6.5, 5.5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(f\"Confusion Matrix â€” {name} (test)\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks(range(n_classes)); ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax.set_yticks(range(n_classes)); ax.set_yticklabels(classes)\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            ax.text(j, i, str(cm[i, j]), ha='center', va='center', fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    out_png = OUT / f\"cm_{name.replace(' ', '_')}.png\"\n",
    "    fig.savefig(out_png, dpi=140)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\n",
    "        'name': name, 'val_acc': acc_va, 'val_f1m': f1m_va,\n",
    "        'test_acc': acc_te, 'test_f1m': f1m_te, 'fit_sec': tr_time,\n",
    "        'cm_path': str(out_png)\n",
    "    }"
   ],
   "metadata": {
    "id": "l9f8Att-sWrz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756602599092,
     "user_tz": -180,
     "elapsed": 9,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OPTIONAL PCA"
   ],
   "metadata": {
    "id": "jVpfR4SxsZq6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#\n",
    "#  Train baselines\n",
    "results = []\n",
    "USE_PCA = False\n",
    "\n",
    "# 8.1) Random Forest (GPU) â€” modest sweep\n",
    "rf_grid = [\n",
    "    dict(n_estimators=1000, max_depth=18, max_features=1.0, n_streams=8, bootstrap=True, random_state=42),\n",
    "    dict(n_estimators=1500, max_depth=24, max_features=0.8, n_streams=8, bootstrap=True, random_state=42),\n",
    "]\n",
    "for i, params in enumerate(rf_grid, 1):\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    res = evaluate(f\"RF_{i}\", rf, Xtr, Ytr, Xva, Yva, Xte, Yte, sample_weight=train_weights)\n",
    "    results.append(res)\n",
    "\n",
    "# 8.2) SVM RBF (GPU) â€” grid over C/gamma and PCA sizes\n",
    "svm_C = [1.0, 2.0, 4.0, 8.0, 16.0]\n",
    "svm_gamma = ['scale', 'auto']\n",
    "\n",
    "# Try PCA at 64/128/256 and keep the best\n",
    "PCA_SIZES = [64, 128, 256]\n",
    "svm_results = []\n",
    "for pca_k in PCA_SIZES:\n",
    "    if USE_PCA:\n",
    "        pca_k = int(min(pca_k, Xtr.shape[1]))\n",
    "        pca_k = max(2, pca_k)\n",
    "        print(f\"Fitting GPU PCA for SVM grid: k={pca_k}\")\n",
    "        pca_tmp = PCA(n_components=pca_k)\n",
    "        Xtr_pp = pca_tmp.fit_transform(Xtr)\n",
    "        Xva_pp = pca_tmp.transform(Xva)\n",
    "        Xte_pp = pca_tmp.transform(Xte)\n",
    "    else:\n",
    "        Xtr_pp, Xva_pp, Xte_pp = Xtr, Xva, Xte\n",
    "    for C in svm_C:\n",
    "        for g in svm_gamma:\n",
    "            svc = SVC(C=C, gamma=g, kernel='rbf', max_iter=200000, cache_size=2048)\n",
    "            tag = f\"SVM_RBF_C{C}_G{g}__PCA{pca_k}\"\n",
    "            res = evaluate(tag, svc, Xtr_pp, Ytr, Xva_pp, Yva, Xte_pp, Yte, sample_weight=train_weights)\n",
    "            svm_results.append(res)\n",
    "            results.append(res)\n",
    "\n",
    "# 8.3) Logistic Regression (GPU) â€” a couple of C values\n",
    "log_grid = [\n",
    "    dict(C=1.0, penalty='l2', max_iter=4000, tol=1e-4, fit_intercept=True),\n",
    "    dict(C=0.5, penalty='l2', max_iter=4000, tol=1e-4, fit_intercept=True),\n",
    "]\n",
    "for i, params in enumerate(log_grid, 1):\n",
    "    lr = LogisticRegression(**params)\n",
    "    res = evaluate(f\"LogReg_{i}\", lr, Xtr, Ytr, Xva, Yva, Xte, Yte, sample_weight=train_weights)\n",
    "    results.append(res)\n",
    "\n",
    "# 8.4) KNN (GPU) â€” try a wider k sweep with PCA=64/128\n",
    "for k in [5, 9, 13, 21]:\n",
    "    for pca_k in [64, 128]:\n",
    "        if USE_PCA:\n",
    "            pca_k = int(min(pca_k, Xtr.shape[1]))\n",
    "            pca_tmp = PCA(n_components=pca_k)\n",
    "            Xtr_pp = pca_tmp.fit_transform(Xtr)\n",
    "            Xva_pp = pca_tmp.transform(Xva)\n",
    "            Xte_pp = pca_tmp.transform(Xte)\n",
    "        else:\n",
    "            Xtr_pp, Xva_pp, Xte_pp = Xtr, Xva, Xte\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='euclidean')\n",
    "        res = evaluate(f\"KNN_k{k}__PCA{pca_k}\", knn, Xtr_pp, Ytr, Xva_pp, Yva, Xte_pp, Yte)\n",
    "        results.append(res)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-VSmzJIs0-r",
    "outputId": "b4ef9596-a5f3-436e-fdb7-d4456e483887",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Training RF_1 ===\n",
      "   [Info] Model RF_1 does not support sample_weight. Training without it.\n",
      "RF_1: val acc=0.4493 f1_macro=0.4433 | test acc=0.5543 f1_macro=0.5423 (fit 40.97s)\n",
      "\n",
      "=== Training RF_2 ===\n",
      "   [Info] Model RF_2 does not support sample_weight. Training without it.\n",
      "RF_2: val acc=0.4548 f1_macro=0.4491 | test acc=0.5610 f1_macro=0.5493 (fit 60.47s)\n",
      "\n",
      "=== Training SVM_RBF_C1.0_Gscale__PCA64 ===\n",
      "[2025-08-31 01:11:53.188] [CUML] [warning] Sample weights are currently ignored for multi class classification\n",
      "SVM_RBF_C1.0_Gscale__PCA64: val acc=0.3520 f1_macro=0.3496 | test acc=0.4048 f1_macro=0.3664 (fit 1.01s)\n",
      "\n",
      "=== Training SVM_RBF_C1.0_Gauto__PCA64 ===\n",
      "[2025-08-31 01:11:54.583] [CUML] [warning] Sample weights are currently ignored for multi class classification\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 9) XGBoost (GPU) + tuned sweep\n",
    "# ---------------------------\n",
    "TRY_XGB = True\n",
    "if TRY_XGB:\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        dtrain = xgb.DMatrix(_to_cpu(X_tr), label=_to_cpu(Y_tr))\n",
    "        dval   = xgb.DMatrix(_to_cpu(X_va), label=_to_cpu(Y_va))\n",
    "        dtest  = xgb.DMatrix(_to_cpu(X_te), label=_to_cpu(Y_te))\n",
    "\n",
    "        xgb_grid = [\n",
    "            dict(max_depth=6,  eta=0.10, subsample=0.9, colsample_bytree=0.9),\n",
    "            dict(max_depth=8,  eta=0.08, subsample=0.9, colsample_bytree=0.9),\n",
    "            dict(max_depth=10, eta=0.06, subsample=0.9, colsample_bytree=0.9),\n",
    "        ]\n",
    "        for i, hp in enumerate(xgb_grid, 1):\n",
    "            params = dict(\n",
    "                objective='multi:softprob', num_class=n_classes,\n",
    "                tree_method='gpu_hist', reg_lambda=1.0, max_bin=256, eval_metric='mlogloss',\n",
    "                **hp\n",
    "            )\n",
    "            bst = xgb.train(\n",
    "                params, dtrain, num_boost_round=900,\n",
    "                evals=[(dval, 'val')], verbose_eval=False, early_stopping_rounds=50\n",
    "            )\n",
    "            # Use softprob output\n",
    "            pv_prob = bst.predict(dval)\n",
    "            pt_prob = bst.predict(dtest)\n",
    "            pv = np.argmax(pv_prob, axis=1).astype(np.int32)\n",
    "            pt = np.argmax(pt_prob, axis=1).astype(np.int32)\n",
    "\n",
    "            acc_va = accuracy_score(_to_cpu(Yva), pv)\n",
    "            f1m_va = f1_score(_to_cpu(Yva), pv, average='macro')\n",
    "            acc_te = accuracy_score(_to_cpu(Yte), pt)\n",
    "            f1m_te = f1_score(_to_cpu(Yte), pt, average='macro')\n",
    "            name = f\"XGB_gpu_hist_{i}\"\n",
    "            print(f\"{name}: val acc={acc_va:.4f} f1_macro={f1m_va:.4f} | test acc={acc_te:.4f} f1_macro={f1m_te:.4f}\")\n",
    "\n",
    "            # Save CM for each XGB run\n",
    "            cm = confusion_matrix(_to_cpu(Yte), pt, labels=list(range(n_classes)))\n",
    "            fig = plt.figure(figsize=(6.5, 5.5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.imshow(cm, interpolation='nearest')\n",
    "            ax.set_title(f\"Confusion Matrix â€” {name} (test)\")\n",
    "            ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "            ax.set_xticks(range(n_classes)); ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "            ax.set_yticks(range(n_classes)); ax.set_yticklabels(classes)\n",
    "            for r in range(n_classes):\n",
    "                for c in range(n_classes):\n",
    "                    ax.text(c, r, str(cm[r, c]), ha='center', va='center', fontsize=8)\n",
    "            out_png = OUT / f\"cm_{name}.png\"\n",
    "            fig.tight_layout(); fig.savefig(out_png, dpi=140); plt.close(fig)\n",
    "\n",
    "            results.append({\n",
    "                'name': name, 'val_acc': acc_va, 'val_f1m': f1m_va,\n",
    "                'test_acc': acc_te, 'test_f1m': f1m_te, 'fit_sec': math.nan,\n",
    "                'cm_path': str(out_png)\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] XGBoost GPU couldn't run:\", e)"
   ],
   "metadata": {
    "id": "vHiKnXqGvUUd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601401141,
     "user_tz": -180,
     "elapsed": 16237,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    },
    "outputId": "e8c317e5-13fb-4469-c158-9640f0daf14c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [00:49:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [00:49:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [00:49:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "XGB_gpu_hist_1: val acc=0.5344 f1_macro=0.5108 | test acc=0.5957 f1_macro=0.5848\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [00:49:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [00:49:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "XGB_gpu_hist_2: val acc=0.5180 f1_macro=0.4944 | test acc=0.5848 f1_macro=0.5736\n",
      "XGB_gpu_hist_3: val acc=0.5141 f1_macro=0.4963 | test acc=0.5890 f1_macro=0.5784\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [00:49:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 10) Results table\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(['val_f1m','test_f1m'], ascending=False)\n",
    "print(\"\\n=== Summary (sorted by val macro-F1) ===\")\n",
    "print(df[['name','val_acc','val_f1m','test_acc','test_f1m','fit_sec','cm_path']].to_string(index=False))\n",
    "\n",
    "# Save\n",
    "CSV_PATH = OUT / 'summary.csv'\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"\\nSaved summary to: {CSV_PATH}\")\n",
    "print(f\"Confusion matrices saved under: {OUT.resolve()}\")\n",
    "\n",
    "# You can download the results folder like this in Colab:\n",
    "# !zip -r results.zip results"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1aigPGSxweP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601415139,
     "user_tz": -180,
     "elapsed": 63,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    },
    "outputId": "ebbff09b-0723-431e-cc31-c474c5ed0e32"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Summary (sorted by val macro-F1) ===\n",
      "                        name  val_acc  val_f1m  test_acc  test_f1m   fit_sec                                         cm_path\n",
      "                    LogReg_2 0.618389 0.601885  0.532581  0.530308  1.082034                     gpu_results/cm_LogReg_2.png\n",
      "                    LogReg_1 0.613940 0.596495  0.529240  0.527809  1.936371                     gpu_results/cm_LogReg_1.png\n",
      " SVM_RBF_C8.0_Gscale__PCA256 0.593178 0.573039  0.525898  0.517650  0.602472  gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA256.png\n",
      "SVM_RBF_C16.0_Gscale__PCA256 0.590707 0.570107  0.525063  0.516115  0.661877 gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA256.png\n",
      " SVM_RBF_C4.0_Gscale__PCA256 0.590707 0.568976  0.533417  0.527276  0.507732  gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA256.png\n",
      " SVM_RBF_C2.0_Gscale__PCA256 0.582798 0.562071  0.544277  0.539337  0.400275  gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA256.png\n",
      " SVM_RBF_C1.0_Gscale__PCA256 0.572417 0.552231  0.557226  0.553346  0.317666  gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA256.png\n",
      " SVM_RBF_C4.0_Gscale__PCA128 0.565497 0.543942  0.523810  0.518727  0.465081  gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA128.png\n",
      " SVM_RBF_C2.0_Gscale__PCA128 0.561048 0.539373  0.540518  0.536181  0.324907  gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA128.png\n",
      " SVM_RBF_C8.0_Gscale__PCA128 0.561542 0.538675  0.509190  0.502491  0.605179  gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA128.png\n",
      "SVM_RBF_C16.0_Gscale__PCA128 0.560554 0.538003  0.502506  0.493081  0.708927 gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA128.png\n",
      " SVM_RBF_C1.0_Gscale__PCA128 0.557093 0.535120  0.560986  0.556640  0.262257  gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA128.png\n",
      "  SVM_RBF_C1.0_Gscale__PCA64 0.542758 0.525235  0.568505  0.562632  1.431023   gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA64.png\n",
      "  SVM_RBF_C4.0_Gscale__PCA64 0.542758 0.522117  0.547201  0.543241  0.370730   gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA64.png\n",
      "  SVM_RBF_C8.0_Gscale__PCA64 0.543747 0.522112  0.540936  0.537964  0.546511   gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA64.png\n",
      "  SVM_RBF_C2.0_Gscale__PCA64 0.541770 0.521533  0.558480  0.552590  0.278417   gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA64.png\n",
      " SVM_RBF_C16.0_Gscale__PCA64 0.538309 0.516588  0.512531  0.511098  0.777824  gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA64.png\n",
      "              XGB_gpu_hist_1 0.534355 0.510782  0.595656  0.584755       NaN               gpu_results/cm_XGB_gpu_hist_1.png\n",
      "  SVM_RBF_C2.0_Gauto__PCA256 0.519525 0.509415  0.507519  0.500649  0.710971   gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA256.png\n",
      "  SVM_RBF_C4.0_Gauto__PCA256 0.519031 0.508863  0.507519  0.500587  0.709593   gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA256.png\n",
      "  SVM_RBF_C8.0_Gauto__PCA256 0.519031 0.508863  0.507519  0.500587  0.702568   gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA256.png\n",
      " SVM_RBF_C16.0_Gauto__PCA256 0.519031 0.508863  0.507519  0.500587  0.707270  gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA256.png\n",
      "  SVM_RBF_C1.0_Gauto__PCA256 0.512605 0.502381  0.503342  0.496497  0.662193   gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA256.png\n",
      "              XGB_gpu_hist_3 0.514088 0.496278  0.588972  0.578430       NaN               gpu_results/cm_XGB_gpu_hist_3.png\n",
      "              XGB_gpu_hist_2 0.518043 0.494426  0.584795  0.573569       NaN               gpu_results/cm_XGB_gpu_hist_2.png\n",
      "                        RF_2 0.456253 0.450317  0.559315  0.547180 60.486319                         gpu_results/cm_RF_2.png\n",
      "                        RF_1 0.448838 0.443023  0.554302  0.542239 41.477016                         gpu_results/cm_RF_1.png\n",
      "  SVM_RBF_C2.0_Gauto__PCA128 0.434009 0.424240  0.403509  0.379479  0.647045   gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA128.png\n",
      "  SVM_RBF_C4.0_Gauto__PCA128 0.433515 0.423590  0.403509  0.379479  0.651029   gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA128.png\n",
      "  SVM_RBF_C8.0_Gauto__PCA128 0.433515 0.423590  0.403509  0.379479  0.653191   gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA128.png\n",
      " SVM_RBF_C16.0_Gauto__PCA128 0.433515 0.423590  0.403509  0.379479  0.650424  gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA128.png\n",
      "  SVM_RBF_C1.0_Gauto__PCA128 0.428077 0.417280  0.393066  0.366197  0.626948   gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA128.png\n",
      "               KNN_k9__PCA64 0.435492 0.411425  0.472431  0.460090  0.001774                gpu_results/cm_KNN_k9__PCA64.png\n",
      "              KNN_k5__PCA128 0.433515 0.409417  0.454887  0.437908  0.001669               gpu_results/cm_KNN_k5__PCA128.png\n",
      "             KNN_k21__PCA128 0.443401 0.408185  0.461153  0.436312  0.001742              gpu_results/cm_KNN_k21__PCA128.png\n",
      "              KNN_k21__PCA64 0.433020 0.405054  0.483709  0.470048  0.001616               gpu_results/cm_KNN_k21__PCA64.png\n",
      "               KNN_k5__PCA64 0.421651 0.401537  0.460735  0.448577  0.001678                gpu_results/cm_KNN_k5__PCA64.png\n",
      "              KNN_k13__PCA64 0.427088 0.400843  0.476190  0.464642  0.001601               gpu_results/cm_KNN_k13__PCA64.png\n",
      "             KNN_k13__PCA128 0.432526 0.398632  0.456976  0.435538  0.001696              gpu_results/cm_KNN_k13__PCA128.png\n",
      "              KNN_k9__PCA128 0.415225 0.383468  0.457393  0.437611  0.001825               gpu_results/cm_KNN_k9__PCA128.png\n",
      "   SVM_RBF_C2.0_Gauto__PCA64 0.348492 0.286514  0.337510  0.268055  0.608385    gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA64.png\n",
      "   SVM_RBF_C4.0_Gauto__PCA64 0.348492 0.286514  0.337510  0.268055  0.604937    gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA64.png\n",
      "   SVM_RBF_C8.0_Gauto__PCA64 0.348492 0.286514  0.337510  0.268055  0.604127    gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA64.png\n",
      "  SVM_RBF_C16.0_Gauto__PCA64 0.348492 0.286514  0.337510  0.268055  0.604326   gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA64.png\n",
      "   SVM_RBF_C1.0_Gauto__PCA64 0.347504 0.284992  0.335422  0.263828  0.601627    gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA64.png\n",
      "\n",
      "Saved summary to: gpu_results/summary.csv\n",
      "Confusion matrices saved under: /content/gpu_results\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r results.zip /content/gpu_results\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aI1DZgFYyEeP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601431407,
     "user_tz": -180,
     "elapsed": 143,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    },
    "outputId": "28ceff71-93fe-4256-c5b8-a003a0c2cd17"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  adding: content/gpu_results/ (stored 0%)\n",
      "  adding: content/gpu_results/cm_KNN_k13__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_RF_2.png (deflated 16%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA128.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA64.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA128.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_LogReg_1.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_XGB_gpu_hist_2.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_LogReg_2.png (deflated 16%)\n",
      "  adding: content/gpu_results/cm_KNN_k21__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_XGB_gpu_hist_1.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gauto__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_KNN_k5__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_XGB_gpu_hist_3.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA64.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA64.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA64.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gscale__PCA128.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_KNN_k13__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/summary.csv (deflated 69%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_RF_1.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gauto__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_KNN_k21__PCA128.png (deflated 16%)\n",
      "  adding: content/gpu_results/cm_KNN_k9__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C8.0_Gscale__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C1.0_Gauto__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gscale__PCA64.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gscale__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C16.0_Gauto__PCA128.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C4.0_Gscale__PCA256.png (deflated 14%)\n",
      "  adding: content/gpu_results/cm_KNN_k5__PCA64.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_SVM_RBF_C2.0_Gauto__PCA256.png (deflated 15%)\n",
      "  adding: content/gpu_results/cm_KNN_k9__PCA128.png (deflated 15%)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bst.save_model(\"xgb_gpu_hist_1.json\")   # or \"xgb_gpu_hist_1.ubj\" (smaller/faster)\n",
    "import json, numpy as np\n",
    "meta = {\n",
    "    \"classes\": classes,                 # label names\n",
    "    \"n_classes\": int(len(classes)),\n",
    "    \"feature_dim\": int(np.shape(X_tr)[1]),\n",
    "    \"preprocessing\": \"features_scaled\", # reminder on whats been used\n",
    "}\n",
    "json.dump(meta, open(\"xgb_gpu_hist_1.meta.json\",\"w\"))\n"
   ],
   "metadata": {
    "id": "MFhCj5vAz76v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756601843986,
     "user_tz": -180,
     "elapsed": 120,
     "user": {
      "displayName": "azzam",
      "userId": "01802553021251542630"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For later loading"
   ],
   "metadata": {
    "id": "dC0lMCmTqivm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(\"xgb_gpu_hist_1.json\")\n",
    "\n",
    "# Force CPU inference\n",
    "bst.set_param({\"predictor\": \"cpu_predictor\"})\n",
    "\n",
    "# Example: run on new data (must be preprocessed the same way as training!)\n",
    "X_new = X_te.astype(np.float32)   # replace with a new example\n",
    "dnew = xgb.DMatrix(X_new)\n",
    "\n",
    "# Get predictions\n",
    "proba = bst.predict(dnew)         # shape (n_samples, n_classes)\n",
    "preds = proba.argmax(axis=1)      # class indices"
   ],
   "metadata": {
    "id": "STHTC6oJoP8f"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
