{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "#!python rapidsai-csp-utils/colab/pip-install.py\n"
   ],
   "metadata": {
    "id": "b7XU2xums58p",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "outputId": "3c5badfb-d9cb-42f3-f5c4-bcdcf0b8cd59"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "#!pip install pandas pyarrow numpy tqdm soundfile cloudpickle scikit-learn joblib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --index-url https://download.pytorch.org/whl/cpu torch==2.5.1 torchaudio==2.5.1\n",
    "!pip install pandas pyarrow numpy tqdm soundfile cloudpickle scikit-learn joblib\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data reading from .wav files .. loading into a df. with filepath for name extraction"
   ],
   "metadata": {
    "id": "VC_9NQV5vL51"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ===== UNIFIED MANIFEST (drop-in) =====\n",
    "from pathlib import Path\n",
    "import re, pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- POINT THESE TO YOUR FOLDERS ---\n",
    "ROOTS = {\n",
    "    # CREMA-D files directly here, e.g. 1001_IEO_HAP_LO.wav\n",
    "    \"CREMA-D\":   Path(\"data/CREMA-D\"),\n",
    "    # ESD speakers directly here, e.g. data/ESD/0011/Angry/0011_000351.wav\n",
    "    \"ESD\":       Path(\"data/ESD\"),\n",
    "    # JL-CORPUS files directly here, e.g. female1_angry_1a_1.wav\n",
    "    \"JL-CORPUS\": Path(\"data/JL-CORPUS\"),\n",
    "    # RAVDESS parent that contains Actor_01..Actor_24\n",
    "    \"RAVDESS\":   Path(\"data/RAVDESS\"),\n",
    "    # TESS files directly here, e.g. OAF_back_neutral.wav\n",
    "    \"TESS\":      Path(\"data/TESS\"),\n",
    "}\n",
    "\n",
    "CANON = {\"angry\",\"happy\",\"neutral\",\"sad\"}\n",
    "\n",
    "def _norm_emo(x:str|None):\n",
    "    if not x: return None\n",
    "    t = x.strip().lower()\n",
    "    aliases = {\n",
    "        \"ang\":\"angry\",\"anger\":\"angry\",\n",
    "        \"hap\":\"happy\",\"happiness\":\"happy\",\n",
    "        \"neu\":\"neutral\",\"calm\":\"neutral\",   # safety fold\n",
    "        \"sadness\":\"sad\",\n",
    "    }\n",
    "    t = aliases.get(t, t)\n",
    "    return t if t in CANON else None\n",
    "\n",
    "# ---------- CREMA-D (1001_IEO_HAP_LO.wav) ----------\n",
    "_pat_cremad = re.compile(r\"^(?P<spk>\\d{4})_[A-Z]{3}_(?P<emo>[A-Z]{3})_[A-Z]{2}\\.(?:wav|WAV)$\")\n",
    "CREMA_MAP = {\"ANG\":\"angry\",\"HAP\":\"happy\",\"NEU\":\"neutral\",\"SAD\":\"sad\"}\n",
    "\n",
    "def parse_cremad(root:Path, diag):\n",
    "    rows=[]\n",
    "    if not root.exists():\n",
    "        diag.append((\"CREMA-D\",\"root_missing\",str(root))); return rows\n",
    "    for p in root.rglob(\"*.wav\"):\n",
    "        m = _pat_cremad.match(p.name)\n",
    "        if not m: diag.append((\"CREMA-D\",\"name_pattern_miss\",str(p))); continue\n",
    "        emo = _norm_emo(CREMA_MAP.get(m.group(\"emo\")))\n",
    "        if not emo: diag.append((\"CREMA-D\",\"emo_not_in_4\",str(p))); continue\n",
    "        rows.append({\"dataset\":\"CREMA-D\",\"filepath\":str(p),\"speaker_id\":m.group(\"spk\"),\"emotion\":emo})\n",
    "    return rows\n",
    "\n",
    "# ---------- ESD (ESD/0011/Angry/0011_000351.wav) ----------\n",
    "def parse_esd(root:Path, diag):\n",
    "    rows=[]\n",
    "    if not root.exists():\n",
    "        diag.append((\"ESD\",\"root_missing\",str(root))); return rows\n",
    "    # speaker folders are numeric (3–5 digits), e.g., 0011..0020\n",
    "    for spk_dir in root.iterdir():\n",
    "        if not (spk_dir.is_dir() and re.fullmatch(r\"\\d{3,5}\", spk_dir.name)):\n",
    "            continue\n",
    "        spk = spk_dir.name\n",
    "        for emo_dir in spk_dir.iterdir():\n",
    "            if not emo_dir.is_dir(): continue\n",
    "            emo = _norm_emo(emo_dir.name)\n",
    "            if not emo: continue\n",
    "            for p in emo_dir.glob(\"*.wav\"):\n",
    "                rows.append({\"dataset\":\"ESD\",\"filepath\":str(p),\"speaker_id\":spk,\"emotion\":emo})\n",
    "    if not rows:\n",
    "        diag.append((\"ESD\",\"no_matches_found\",str(root)))\n",
    "    return rows\n",
    "\n",
    "# ---------- JL-CORPUS (female1_angry_1a_1.wav) ----------\n",
    "_pat_tess_suffix = re.compile(r\"_(angry|happy|neutral|sad)\\.(?:wav|WAV)$\", re.IGNORECASE)\n",
    "\n",
    "def parse_jl(root:Path, diag):\n",
    "    rows=[]\n",
    "    if not root.exists():\n",
    "        diag.append((\"JL-CORPUS\",\"root_missing\",str(root))); return rows\n",
    "    for p in root.rglob(\"*.wav\"):\n",
    "        emo = None\n",
    "        m = _pat_tess_suffix.search(p.name)\n",
    "        if m:\n",
    "            emo = _norm_emo(m.group(1))\n",
    "        else:\n",
    "            tokens = re.split(r\"[_\\-\\s]+\", p.stem)\n",
    "            for tok in tokens:\n",
    "                e = _norm_emo(tok)\n",
    "                if e: emo = e; break\n",
    "        if not emo: diag.append((\"JL-CORPUS\",\"no_emo_in_name\",str(p))); continue\n",
    "        speaker = re.split(r\"[_\\-\\s]+\", p.stem)[0] or p.parent.name\n",
    "        rows.append({\"dataset\":\"JL-CORPUS\",\"filepath\":str(p),\"speaker_id\":speaker,\"emotion\":emo})\n",
    "    return rows\n",
    "\n",
    "# ---------- RAVDESS (Actor_01/03-01-05-02-01-01-24.wav) ----------\n",
    "_pat_rav = re.compile(r\"^(?P<mod>\\d{2})-(?P<vc>\\d{2})-(?P<emo>\\d{2})-(?P<int>\\d{2})-(?P<stm>\\d{2})-(?P<rep>\\d{2})-(?P<act>\\d{2})\\.(?:wav|WAV)$\")\n",
    "RAV_EMO = {\"01\":\"neutral\",\"03\":\"happy\",\"04\":\"sad\",\"05\":\"angry\"}\n",
    "\n",
    "def parse_ravdess(root:Path, diag, restrict_audio_only=True, restrict_speech_only=True):\n",
    "    rows=[]\n",
    "    if not root.exists():\n",
    "        diag.append((\"RAVDESS\",\"root_missing\",str(root))); return rows\n",
    "    actor_dirs = [d for d in root.glob(\"Actor_*\") if d.is_dir()]\n",
    "    if not actor_dirs:\n",
    "        actor_dirs = [d for d in root.rglob(\"Actor_*\") if d.is_dir()] or [root]\n",
    "    for adir in actor_dirs:\n",
    "        for p in adir.rglob(\"*.wav\"):\n",
    "            m = _pat_rav.match(p.name)\n",
    "            if not m: diag.append((\"RAVDESS\",\"name_pattern_miss\",str(p))); continue\n",
    "            if restrict_audio_only and m.group(\"mod\") != \"03\": continue\n",
    "            if restrict_speech_only and m.group(\"vc\")  != \"01\": continue\n",
    "            emo = RAV_EMO.get(m.group(\"emo\"))\n",
    "            if not emo: continue\n",
    "            rows.append({\"dataset\":\"RAVDESS\",\"filepath\":str(p),\"speaker_id\":m.group(\"act\"),\"emotion\":emo})\n",
    "    return rows\n",
    "\n",
    "# ---------- TESS (OAF_back_neutral.wav) ----------\n",
    "def parse_tess(root:Path, diag):\n",
    "    rows=[]\n",
    "    if not root.exists():\n",
    "        diag.append((\"TESS\",\"root_missing\",str(root))); return rows\n",
    "    for p in root.rglob(\"*.wav\"):\n",
    "        m = _pat_tess_suffix.search(p.name)\n",
    "        emo = _norm_emo(m.group(1)) if m else None\n",
    "        if not emo: diag.append((\"TESS\",\"no_emo_in_suffix\",str(p))); continue\n",
    "        spk = p.stem.split(\"_\",1)[0]  # OAF/YAF\n",
    "        rows.append({\"dataset\":\"TESS\",\"filepath\":str(p),\"speaker_id\":spk,\"emotion\":emo})\n",
    "    return rows\n",
    "\n",
    "# ---------- Build unified manifest ----------\n",
    "def build_unified_manifest(roots:dict,\n",
    "                           restrict_ravdess_audio_only=True,\n",
    "                           restrict_ravdess_speech_only=True):\n",
    "    diag = []\n",
    "    rows = []\n",
    "    rows += parse_cremad(roots.get(\"CREMA-D\", Path()), diag)\n",
    "    rows += parse_esd(roots.get(\"ESD\", Path()), diag)            # <— ESD fixed\n",
    "    rows += parse_jl(roots.get(\"JL-CORPUS\", Path()), diag)\n",
    "    rows += parse_ravdess(roots.get(\"RAVDESS\", Path()), diag,\n",
    "                          restrict_audio_only=restrict_ravdess_audio_only,\n",
    "                          restrict_speech_only=restrict_ravdess_speech_only)\n",
    "    rows += parse_tess(roots.get(\"TESS\", Path()), diag)\n",
    "\n",
    "    manifest = pd.DataFrame(rows)\n",
    "    if manifest.empty:\n",
    "        raise RuntimeError(\"No files parsed. Check ROOTS paths.\")\n",
    "    # keep only 4 classes (safety), ensure file exists, dedupe\n",
    "    manifest = manifest[manifest[\"emotion\"].isin(list(CANON))].copy()\n",
    "    manifest = manifest[manifest[\"filepath\"].apply(lambda s: Path(s).is_file())]\n",
    "    manifest = manifest.drop_duplicates(subset=[\"filepath\"]).reset_index(drop=True)\n",
    "\n",
    "    # composite speaker to avoid cross-dataset leakage\n",
    "    manifest[\"speaker_uid\"] = manifest[\"dataset\"] + \":\" + manifest[\"speaker_id\"]\n",
    "\n",
    "    diag_df = pd.DataFrame(diag, columns=[\"dataset\",\"reason\",\"path\"])\n",
    "    return manifest, diag_df\n",
    "\n",
    "# ---------- Speaker-independent split (same as your code, but use speaker_uid) ----------\n",
    "def speaker_independent_split(df, train=0.8, val=0.1, seed=42, speaker_col=\"speaker_uid\"):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    spk = df[speaker_col].unique()\n",
    "    rng.shuffle(spk)\n",
    "    n = len(spk)\n",
    "    n_tr = int(round(train*n))\n",
    "    n_va = int(round(val*n))\n",
    "    tr, va, te = set(spk[:n_tr]), set(spk[n_tr:n_tr+n_va]), set(spk[n_tr+n_va:])\n",
    "    def tag(s): return \"train\" if s in tr else (\"val\" if s in va else \"test\")\n",
    "    return df.assign(split=df[speaker_col].map(tag))\n",
    "\n",
    "# ---------- USE IT ----------\n",
    "# Ensure this matches your actual tree. For you it’s speakers directly under data/ESD:\n",
    "ROOTS[\"ESD\"] = Path(\"data/ESD\")\n",
    "\n",
    "manifest, diag = build_unified_manifest(\n",
    "    ROOTS,\n",
    "    restrict_ravdess_audio_only=True,   # True = use only audio-only\n",
    "    restrict_ravdess_speech_only=True   # True = use only speech (not song)\n",
    ")\n",
    "\n",
    "print(\"TOTAL parsed:\", len(manifest))\n",
    "print(\"\\nBy dataset:\\n\", manifest[\"dataset\"].value_counts())\n",
    "\n",
    "print(\"\\nBy emotion (all 4 expected):\")\n",
    "print(manifest[\"emotion\"].value_counts().reindex([\"angry\",\"happy\",\"neutral\",\"sad\"]).fillna(0).astype(int))\n",
    "\n",
    "print(\"\\nPer-dataset × emotion:\")\n",
    "print(pd.crosstab(manifest[\"dataset\"], manifest[\"emotion\"])\n",
    "        .reindex(columns=[\"angry\",\"happy\",\"neutral\",\"sad\"])\n",
    "        .fillna(0).astype(int))\n",
    "\n",
    "if not diag.empty:\n",
    "    print(\"\\nSkip reasons (top 12):\")\n",
    "    print(diag.groupby([\"dataset\",\"reason\"]).size().sort_values(ascending=False).head(12))\n",
    "\n",
    "# Split by composite speaker id (no leakage)\n",
    "# Defer split — we will do a single stratified, group-aware split below.\n",
    "# manifest = speaker_independent_split(manifest, train=0.8, val=0.1, seed=42, speaker_col=\"speaker_uid\")\n",
    "# print(\"\\nSplit sizes:\\n\", manifest[\"split\"].value_counts())\n",
    "# print(\"\\nClass balance (head):\\n\", manifest.groupby(\"split\")[\"emotion\"].value_counts().head())\n"
   ],
   "metadata": {
    "id": "t1pvjDkDtlNn",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "33b21296-3559-43e8-e9d6-4bda4954f4a5",
    "ExecuteTime": {
     "end_time": "2025-08-31T00:16:41.135082Z",
     "start_time": "2025-08-31T00:16:39.361123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL parsed: 22131\n",
      "\n",
      "By dataset:\n",
      " dataset\n",
      "ESD          14000\n",
      "CREMA-D       4899\n",
      "TESS          1600\n",
      "JL-CORPUS      960\n",
      "RAVDESS        672\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By emotion (all 4 expected):\n",
      "emotion\n",
      "angry      5603\n",
      "happy      5603\n",
      "neutral    5323\n",
      "sad        5602\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Per-dataset × emotion:\n",
      "emotion    angry  happy  neutral   sad\n",
      "dataset                               \n",
      "CREMA-D     1271   1271     1087  1270\n",
      "ESD         3500   3500     3500  3500\n",
      "JL-CORPUS    240    240      240   240\n",
      "RAVDESS      192    192       96   192\n",
      "TESS         400    400      400   400\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split speakers into train/val/test (80/10/10) so that no speaker appears in more than one split to ensure speaker independence\n",
    "### And we want to keep the class distribution roughly similar across splits\n",
    "### To do this, we will randomly shuffle the speakers and assign them to splits\n",
    "### based on the desired proportions.\n",
    "### For reproducibility, use a fixed random seed=42\n"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg-oRftKvzpu",
    "outputId": "35db9374-3315-4520-8dc4-5e650710bda5",
    "ExecuteTime": {
     "end_time": "2025-08-31T00:16:55.838672Z",
     "start_time": "2025-08-31T00:16:55.001825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "def stratified_group_split(df: pd.DataFrame, train=0.8, val=0.1, seed=42,\n",
    "                           label_col=\"emotion\", group_col=\"speaker_uid\"):\n",
    "    \"\"\"\n",
    "    2-stage split using StratifiedGroupKFold:\n",
    "      1) train+val vs test\n",
    "      2) train vs val\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_splits_outer = int(round(1/(1-train-val)))  # e.g., 1/(0.2) = 5\n",
    "    n_splits_outer = max(3, min(10, n_splits_outer))\n",
    "\n",
    "    sgkf_outer = StratifiedGroupKFold(n_splits=n_splits_outer, shuffle=True, random_state=seed)\n",
    "    X = df.index.values\n",
    "    y = df[label_col].values\n",
    "    g = df[group_col].values\n",
    "\n",
    "    # Find a test split closest to target size\n",
    "    target_test = 1 - (train + val)\n",
    "    best = None\n",
    "    for trval_idx, te_idx in sgkf_outer.split(X, y, groups=g):\n",
    "        frac_test = len(te_idx)/len(X)\n",
    "        score = abs(frac_test - target_test)\n",
    "        if (best is None) or (score < best[0]):\n",
    "            best = (score, trval_idx, te_idx)\n",
    "    _, trval_idx, te_idx = best\n",
    "\n",
    "    # Now split train vs val on the tr+val portion\n",
    "    X_tv = X[trval_idx]; y_tv = y[trval_idx]; g_tv = g[trval_idx]\n",
    "    target_val = val/(train+val)\n",
    "    n_splits_inner = int(round(1/target_val))\n",
    "    n_splits_inner = max(3, min(10, n_splits_inner))\n",
    "\n",
    "    sgkf_inner = StratifiedGroupKFold(n_splits=n_splits_inner, shuffle=True, random_state=seed+1)\n",
    "    best2 = None\n",
    "    for tr_idx, va_idx in sgkf_inner.split(X_tv, y_tv, groups=g_tv):\n",
    "        frac_val = len(va_idx)/len(X_tv)\n",
    "        score = abs(frac_val - target_val)\n",
    "        if (best2 is None) or (score < best2[0]):\n",
    "            best2 = (score, tr_idx, va_idx)\n",
    "    _, tr_idx, va_idx = best2\n",
    "\n",
    "    split = pd.Series(index=df.index, dtype=\"object\")\n",
    "    split.iloc[X_tv[tr_idx]] = \"train\"\n",
    "    split.iloc[X_tv[va_idx]] = \"val\"\n",
    "    split.iloc[X[te_idx]]    = \"test\"\n",
    "    return df.assign(split=split)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T00:16:58.315767Z",
     "start_time": "2025-08-31T00:16:58.172681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# after you build `manifest` and add `speaker_uid`\n",
    "manifest = stratified_group_split(manifest, train=0.8, val=0.1, seed=42,\n",
    "                                  label_col=\"emotion\", group_col=\"speaker_uid\")\n",
    "\n",
    "print(manifest[\"split\"].value_counts())\n",
    "print(pd.crosstab(manifest[\"split\"], manifest[\"emotion\"]))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    17714\n",
      "test      2394\n",
      "val       2023\n",
      "Name: count, dtype: int64\n",
      "emotion  angry  happy  neutral   sad\n",
      "split                               \n",
      "test       604    604      582   604\n",
      "train     4485   4485     4260  4484\n",
      "val        514    514      481   514\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract feature into arrays using different torchaudio functions"
   ],
   "metadata": {
    "id": "uJL7sBApxwVD"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T00:17:00.743100Z",
     "start_time": "2025-08-31T00:17:00.650235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json, torch, torchaudio\n",
    "import torchaudio.transforms as T, torchaudio.functional as AF\n",
    "import torch.nn.functional as Fnn\n",
    "\n",
    "# Load your config.json\n",
    "with open(\"config.json\") as f:\n",
    "    CFG = json.load(f)\n",
    "\n",
    "SR = CFG[\"sr\"]; N_FFT = CFG[\"n_fft\"]\n",
    "WIN = int(SR*CFG[\"win_ms\"]/1000); HOP = int(SR*CFG[\"hop_ms\"]/1000)\n",
    "_EPS = 1e-10\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.mel  = T.MelSpectrogram(\n",
    "            sample_rate=SR, n_fft=N_FFT, hop_length=HOP, win_length=WIN,\n",
    "            n_mels=cfg[\"n_mels\"], power=2.0\n",
    "        )\n",
    "        self.mfcc = T.MFCC(\n",
    "            sample_rate=SR, n_mfcc=cfg[\"n_mfcc\"],\n",
    "            melkwargs={\"n_fft\":N_FFT, \"hop_length\":HOP, \"win_length\":WIN, \"n_mels\":cfg[\"n_mels\"]}\n",
    "        )\n",
    "        self.spec = T.Spectrogram(n_fft=N_FFT, hop_length=HOP, win_length=WIN, power=2.0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def from_path(self, path:str) -> np.ndarray:\n",
    "        # load & standardize\n",
    "        y, sr0 = torchaudio.load(path)              # [C, T]\n",
    "        y = y.mean(0, keepdim=True)\n",
    "        if sr0 != SR:\n",
    "            y = torchaudio.functional.resample(y, sr0, SR)\n",
    "        peak = float(y.abs().max())\n",
    "        if peak > 0:\n",
    "            y = y * (self.cfg[\"peak_target\"] / peak)\n",
    "\n",
    "        # frame features\n",
    "        mel = self.mel(y).clamp_min(_EPS)                 # [1, M, F]\n",
    "        logmel = torch.log(mel).squeeze(0).T              # [F, M]\n",
    "\n",
    "        mfcc = self.mfcc(y).squeeze(0).T                  # [F, C]\n",
    "        d1   = AF.compute_deltas(mfcc.T).T\n",
    "        d2   = AF.compute_deltas(d1.T).T\n",
    "\n",
    "        spec = self.spec(y).squeeze(0).clamp_min(_EPS)    # [K, F]\n",
    "        F_frames = spec.shape[1]\n",
    "        freqs = torch.linspace(0, SR/2, spec.shape[0], device=spec.device)\n",
    "        ps = spec                                         # already >= eps\n",
    "\n",
    "        # spectral shape\n",
    "        cen = (freqs[:,None] * ps).sum(0) / ps.sum(0)\n",
    "        bw  = torch.sqrt(((freqs[:,None] - cen[None,:])**2 * ps).sum(0) / ps.sum(0))\n",
    "\n",
    "        # rolloffs (contiguous for searchsorted)\n",
    "        cs = torch.cumsum(ps, dim=0).contiguous()\n",
    "        tot = cs[-1,:].contiguous()\n",
    "        t85 = (0.85*tot).unsqueeze(1).contiguous()\n",
    "        t95 = (0.95*tot).unsqueeze(1).contiguous()\n",
    "        idx85 = torch.searchsorted(cs.T.contiguous(), t85).clamp(max=cs.shape[0]-1).squeeze(1)\n",
    "        idx95 = torch.searchsorted(cs.T.contiguous(), t95).clamp(max=cs.shape[0]-1).squeeze(1)\n",
    "        roll85, roll95 = freqs[idx85], freqs[idx95]\n",
    "\n",
    "        # spectral flatness (geom/arith mean) — numerically safe\n",
    "        geo = torch.exp(torch.log(ps).mean(0))\n",
    "        arith = ps.mean(0).clamp_min(_EPS)\n",
    "        flat = (geo / arith)\n",
    "\n",
    "        # spectral flux (on L2-normalized magnitude)\n",
    "        mag = torch.sqrt(ps)\n",
    "        mag = mag / (mag.norm(p=2, dim=0, keepdim=True).clamp_min(_EPS))\n",
    "        flux = torch.zeros(mag.shape[1], device=mag.device)\n",
    "        flux[1:] = (mag[:,1:] - mag[:,:-1]).pow(2).sum(0).sqrt()\n",
    "\n",
    "        # frame energy in dB (finite by construction)\n",
    "        frame_energy_db = 10.0 * torch.log10(ps.mean(0).clamp_min(_EPS))\n",
    "\n",
    "        # pitch (no hop_length/win_length) + align to spectrogram frames\n",
    "        f0_raw = AF.detect_pitch_frequency(\n",
    "            y, sample_rate=SR, frame_time=self.cfg[\"win_ms\"]/1000.0\n",
    "        ).squeeze(0)                              # [F0_frames]\n",
    "        if f0_raw.numel() == 0:\n",
    "            f0_rs = torch.zeros(F_frames, device=spec.device)\n",
    "        else:\n",
    "            f0_in = f0_raw.clone()\n",
    "            f0_in[f0_in <= 0] = 0.0              # unvoiced -> 0 for interpolation\n",
    "            f0_rs = Fnn.interpolate(\n",
    "                f0_in.view(1,1,-1), size=F_frames, mode=\"linear\", align_corners=False\n",
    "            ).view(-1)\n",
    "        voiced = f0_rs > 0\n",
    "        f0 = torch.where(voiced, f0_rs, torch.nan)       # keep NaN for unvoiced; pooling handles it\n",
    "\n",
    "        # stack frames x dims (KEEPING ALL FEATURES)\n",
    "        F = torch.cat([\n",
    "            mfcc, d1, d2,\n",
    "            logmel,\n",
    "            torch.stack([cen, bw, roll85, roll95, flat, flux, frame_energy_db], dim=1),\n",
    "            f0.unsqueeze(1),\n",
    "        ], dim=1)\n",
    "\n",
    "\n",
    "        F = torch.nan_to_num(F, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # pooling from config (all + voiced-only; fixed size even if no voiced)\n",
    "        def pool(A: torch.Tensor) -> torch.Tensor:\n",
    "            parts = []\n",
    "            if \"mean\"   in self.cfg[\"pooling\"]: parts.append(A.mean(0))\n",
    "            if \"std\"    in self.cfg[\"pooling\"]: parts.append(A.std(0))\n",
    "            if \"median\" in self.cfg[\"pooling\"]: parts.append(A.median(0).values)\n",
    "            if \"p10\"    in self.cfg[\"pooling\"]: parts.append(torch.quantile(A, 0.10, dim=0))\n",
    "            if \"p90\"    in self.cfg[\"pooling\"]: parts.append(torch.quantile(A, 0.90, dim=0))\n",
    "            if \"slope\"  in self.cfg[\"pooling\"]:\n",
    "                t = torch.linspace(0, 1, A.shape[0], device=A.device).unsqueeze(1)\n",
    "                den = ((t - t.mean())**2).sum().clamp_min(1e-9)\n",
    "                slope = (t * (A - A.mean(0))).sum(0) / den\n",
    "                parts.append(slope)\n",
    "            return torch.cat(parts, 0)\n",
    "\n",
    "        v_all = pool(F)\n",
    "        # voiced stats vector (same length as v_all); if no voiced frames, fill zeros to keep dimension\n",
    "        if self.cfg.get(\"voiced_variant\", True):\n",
    "            if voiced.any():                v_vo = pool(F[voiced])\n",
    "            else:\n",
    "                v_vo = torch.zeros_like(v_all)\n",
    "            v = torch.cat([v_all, v_vo], 0)\n",
    "        else:\n",
    "            v = v_all\n",
    "\n",
    "        v = torch.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return v.float().cpu().numpy()\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "## Actual extracting (Raw features, no scaling yet can save this if we want to)",
   "metadata": {
    "id": "dnHdnN1t67Xq"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T00:24:24.711135Z",
     "start_time": "2025-08-31T00:24:24.702980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parallel extraction helpers\n",
    "\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# prevent thread oversubscription when using process-level parallelism\n",
    "# if we dont set this each core will spawn its own threads which will lead to\n",
    "# threads fighting over the process .. and overall instead of\n",
    "# making this faster, we make it slower.\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"TORCH_NUM_THREADS\", \"1\")\n",
    "# Recycle workers to mitigate native leaks in long jobs\n",
    "os.environ.setdefault(\"LOKY_MAX_JOBS_BEFORE_RESTART\", \"256\")\n",
    "\n",
    "def _infer_dim_from_any(df_subset, cfg):\n",
    "    fx = FeatureExtractor(cfg)\n",
    "    for path in df_subset[\"filepath\"]:\n",
    "        try:\n",
    "            return fx.from_path(path).shape[0]\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise RuntimeError(\"Cannot infer feature dimension from subset (all failures).\")\n",
    "\n",
    "def _process_row(row, cfg, feature_dim):\n",
    "    try:\n",
    "        fx = FeatureExtractor(cfg)\n",
    "        v = fx.from_path(row.filepath)\n",
    "        return v, row.emotion\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] {row.filepath}: {e}\")\n",
    "        return np.zeros((feature_dim,), dtype=np.float32), row.emotion\n",
    "\n",
    "def build_Xy_parallel(df_subset, cfg, n_jobs=-1, desc=\"extract\"):\n",
    "    rows = list(df_subset.itertuples(index=False))\n",
    "    feat_dim = _infer_dim_from_any(df_subset, cfg)\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_process_row)(row, cfg, feat_dim) for row in tqdm(rows, desc=desc)\n",
    "    )\n",
    "    X_list, y_list = zip(*results) if results else ([], [])\n",
    "    X = np.vstack(X_list).astype(np.float32) if X_list else np.zeros((0, feat_dim), dtype=np.float32)\n",
    "    y = pd.Series(y_list).astype(str)  # keep strings here; encode once from TRAIN\n",
    "    return X, y\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# 7) Extract splits (parallel) + encode labels consistently\n",
    "\n",
    "# choose your parallelism; -1 = all cores\n",
    "# Set to a fixed number i.e. 5 = 5 cores if too much work\n",
    "N_JOBS = -1\n",
    "\n",
    "# TRAIN FIRST to lock class mapping\n",
    "X_train, y_train_labels = build_Xy_parallel(manifest[manifest.split==\"train\"], CFG, n_jobs=N_JOBS, desc=\"train\")\n",
    "\n",
    "# choose a deterministic class order\n",
    "# classes = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\"]\n",
    "\"\"\"\n",
    "{'angry': 0, 'happy': 1, 'neutral': 2, 'sad': 3}\n",
    "\n",
    "\"\"\"\n",
    "classes = sorted(pd.unique(y_train_labels))\n",
    "class_to_id = {c:i for i,c in enumerate(classes)}\n",
    "y_train = np.array([class_to_id[s] for s in y_train_labels], dtype=np.int64)\n",
    "\n",
    "# VAL\n",
    "X_val, y_val_labels = build_Xy_parallel(manifest[manifest.split==\"val\"], CFG, n_jobs=N_JOBS, desc=\"val\")\n",
    "y_val = np.array([class_to_id.get(s, -1) for s in y_val_labels], dtype=np.int64)\n",
    "if (y_val < 0).any():\n",
    "    missing = sorted(set(y_val_labels[np.where(y_val<0)[0]]))\n",
    "    print(\"[warn] val labels not seen in train:\", missing)\n",
    "\n",
    "# TEST\n",
    "X_test, y_test_labels = build_Xy_parallel(manifest[manifest.split==\"test\"], CFG, n_jobs=N_JOBS, desc=\"test\")\n",
    "y_test = np.array([class_to_id.get(s, -1) for s in y_test_labels], dtype=np.int64)\n",
    "if (y_test < 0).any():\n",
    "    missing = sorted(set(y_test_labels[np.where(y_test<0)[0]]))\n",
    "    print(\"[warn] test labels not seen in train:\", missing)\n",
    "\n",
    "print(\"dims:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"classes:\", classes)\n",
    "print(\"NaNs in train:\", np.isnan(X_train).sum())\n"
   ],
   "metadata": {
    "id": "Wui2PAdBPfhk",
    "ExecuteTime": {
     "end_time": "2025-08-31T00:36:07.310840Z",
     "start_time": "2025-08-31T00:24:26.783156Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train:   0%|          | 0/17714 [00:00<?, ?it/s]\u001B[A\n",
      "train:   0%|          | 22/17714 [00:00<03:09, 93.12it/s]\u001B[A\n",
      "train:   0%|          | 44/17714 [00:04<33:41,  8.74it/s]\u001B[A\n",
      "train:   0%|          | 66/17714 [00:04<19:24, 15.16it/s]\u001B[A\n",
      "train:   0%|          | 88/17714 [00:04<12:37, 23.27it/s]\u001B[A\n",
      "train:   1%|          | 110/17714 [00:04<08:37, 34.05it/s]\u001B[A\n",
      "train:   1%|          | 132/17714 [00:04<06:15, 46.84it/s]\u001B[A\n",
      "train:   1%|          | 154/17714 [00:05<04:40, 62.57it/s]\u001B[A\n",
      "train:   1%|          | 176/17714 [00:05<03:39, 79.82it/s]\u001B[A\n",
      "train:   1%|          | 198/17714 [00:05<02:59, 97.60it/s]\u001B[A\n",
      "train:   1%|          | 220/17714 [00:05<02:31, 115.33it/s]\u001B[A\n",
      "train:   1%|▏         | 242/17714 [00:05<02:13, 130.63it/s]\u001B[A\n",
      "train:   1%|▏         | 264/17714 [00:05<02:00, 145.24it/s]\u001B[A\n",
      "train:   2%|▏         | 286/17714 [00:05<01:53, 153.21it/s]\u001B[A\n",
      "train:   2%|▏         | 308/17714 [00:05<01:48, 159.72it/s]\u001B[A\n",
      "train:   2%|▏         | 330/17714 [00:06<01:46, 162.60it/s]\u001B[A\n",
      "train:   2%|▏         | 352/17714 [00:06<01:43, 166.95it/s]\u001B[A\n",
      "train:   2%|▏         | 374/17714 [00:06<01:41, 171.16it/s]\u001B[A\n",
      "train:   2%|▏         | 396/17714 [00:06<01:38, 175.67it/s]\u001B[A\n",
      "train:   2%|▏         | 418/17714 [00:06<01:36, 178.52it/s]\u001B[A\n",
      "train:   2%|▏         | 440/17714 [00:06<01:34, 182.45it/s]\u001B[A\n",
      "train:   3%|▎         | 462/17714 [00:06<01:32, 186.82it/s]\u001B[A\n",
      "train:   3%|▎         | 484/17714 [00:06<01:32, 186.33it/s]\u001B[A\n",
      "train:   3%|▎         | 506/17714 [00:06<01:33, 184.41it/s]\u001B[A\n",
      "train:   3%|▎         | 528/17714 [00:07<01:32, 185.06it/s]\u001B[A\n",
      "train:   3%|▎         | 550/17714 [00:07<01:32, 184.98it/s]\u001B[A\n",
      "train:   3%|▎         | 572/17714 [00:07<01:30, 188.40it/s]\u001B[A\n",
      "train:   3%|▎         | 594/17714 [00:07<01:29, 190.66it/s]\u001B[A\n",
      "train:   4%|▎         | 638/17714 [00:07<01:24, 201.05it/s]\u001B[A\n",
      "train:   4%|▍         | 682/17714 [00:07<01:07, 251.02it/s]\u001B[A\n",
      "train:   4%|▍         | 726/17714 [00:07<00:59, 283.61it/s]\u001B[A\n",
      "train:   4%|▍         | 770/17714 [00:08<01:02, 273.27it/s]\u001B[A\n",
      "train:   5%|▍         | 814/17714 [00:08<01:07, 250.68it/s]\u001B[A\n",
      "train:   5%|▍         | 858/17714 [00:08<01:04, 259.54it/s]\u001B[A\n",
      "train:   5%|▌         | 902/17714 [00:08<01:09, 241.56it/s]\u001B[A\n",
      "train:   5%|▌         | 946/17714 [00:08<01:06, 251.48it/s]\u001B[A\n",
      "train:   6%|▌         | 990/17714 [00:09<01:15, 222.85it/s]\u001B[A\n",
      "train:   6%|▌         | 1034/17714 [00:09<01:16, 218.37it/s]\u001B[A\n",
      "train:   6%|▌         | 1078/17714 [00:09<01:20, 205.99it/s]\u001B[A\n",
      "train:   6%|▋         | 1122/17714 [00:09<01:17, 213.34it/s]\u001B[A\n",
      "train:   7%|▋         | 1166/17714 [00:09<01:13, 224.39it/s]\u001B[A\n",
      "train:   7%|▋         | 1210/17714 [00:09<01:12, 227.79it/s]\u001B[A\n",
      "train:   7%|▋         | 1254/17714 [00:10<01:16, 216.54it/s]\u001B[A\n",
      "train:   7%|▋         | 1298/17714 [00:10<01:12, 226.50it/s]\u001B[A\n",
      "train:   8%|▊         | 1342/17714 [00:10<01:11, 227.48it/s]\u001B[A\n",
      "train:   8%|▊         | 1386/17714 [00:10<01:13, 222.25it/s]\u001B[A\n",
      "train:   8%|▊         | 1430/17714 [00:10<01:09, 234.25it/s]\u001B[A\n",
      "train:   8%|▊         | 1474/17714 [00:11<01:11, 227.69it/s]\u001B[A\n",
      "train:   9%|▊         | 1518/17714 [00:11<01:13, 219.56it/s]\u001B[A\n",
      "train:   9%|▉         | 1562/17714 [00:11<01:13, 219.16it/s]\u001B[A\n",
      "train:   9%|▉         | 1606/17714 [00:11<01:14, 217.60it/s]\u001B[A\n",
      "train:   9%|▉         | 1650/17714 [00:11<01:13, 218.71it/s]\u001B[A\n",
      "train:  10%|▉         | 1694/17714 [00:12<01:11, 222.72it/s]\u001B[A\n",
      "train:  10%|▉         | 1738/17714 [00:12<01:13, 217.03it/s]\u001B[A\n",
      "train:  10%|█         | 1782/17714 [00:12<01:11, 222.91it/s]\u001B[A\n",
      "train:  10%|█         | 1826/17714 [00:12<01:08, 233.64it/s]\u001B[A\n",
      "train:  11%|█         | 1870/17714 [00:12<01:10, 224.85it/s]\u001B[A\n",
      "train:  11%|█         | 1914/17714 [00:13<01:12, 219.31it/s]\u001B[A\n",
      "train:  11%|█         | 1958/17714 [00:13<01:11, 220.18it/s]\u001B[A\n",
      "train:  11%|█▏        | 2002/17714 [00:13<01:09, 227.64it/s]\u001B[A\n",
      "train:  12%|█▏        | 2046/17714 [00:13<01:14, 209.90it/s]\u001B[A\n",
      "train:  12%|█▏        | 2090/17714 [00:13<01:12, 216.09it/s]\u001B[A\n",
      "train:  12%|█▏        | 2134/17714 [00:14<01:09, 223.15it/s]\u001B[A\n",
      "train:  12%|█▏        | 2178/17714 [00:14<01:11, 217.55it/s]\u001B[A\n",
      "train:  13%|█▎        | 2222/17714 [00:14<01:14, 208.27it/s]\u001B[A\n",
      "train:  13%|█▎        | 2266/17714 [00:14<01:10, 218.76it/s]\u001B[A\n",
      "train:  13%|█▎        | 2310/17714 [00:15<01:12, 212.96it/s]\u001B[A\n",
      "train:  13%|█▎        | 2354/17714 [00:15<01:10, 218.66it/s]\u001B[A\n",
      "train:  14%|█▎        | 2398/17714 [00:15<01:14, 205.89it/s]\u001B[A\n",
      "train:  14%|█▍        | 2442/17714 [00:15<01:13, 207.31it/s]\u001B[A\n",
      "train:  14%|█▍        | 2486/17714 [00:15<01:15, 201.14it/s]\u001B[A\n",
      "train:  14%|█▍        | 2530/17714 [00:16<01:14, 204.44it/s]\u001B[A\n",
      "train:  15%|█▍        | 2574/17714 [00:16<01:09, 217.10it/s]\u001B[A\n",
      "train:  15%|█▍        | 2618/17714 [00:16<01:10, 214.54it/s]\u001B[A\n",
      "train:  15%|█▌        | 2662/17714 [00:16<01:09, 215.70it/s]\u001B[A\n",
      "train:  15%|█▌        | 2706/17714 [00:16<01:18, 190.93it/s]\u001B[A\n",
      "train:  16%|█▌        | 2750/17714 [00:17<01:13, 204.10it/s]\u001B[A\n",
      "train:  16%|█▌        | 2794/17714 [00:17<01:12, 206.37it/s]\u001B[A\n",
      "train:  16%|█▌        | 2838/17714 [00:17<01:14, 200.62it/s]\u001B[A\n",
      "train:  16%|█▋        | 2882/17714 [00:17<01:14, 198.00it/s]\u001B[A\n",
      "train:  17%|█▋        | 2926/17714 [00:18<01:15, 196.57it/s]\u001B[A\n",
      "train:  17%|█▋        | 2970/17714 [00:18<01:13, 201.83it/s]\u001B[A\n",
      "train:  17%|█▋        | 3014/17714 [00:18<01:14, 196.59it/s]\u001B[A\n",
      "train:  17%|█▋        | 3058/17714 [00:18<01:14, 195.99it/s]\u001B[A\n",
      "train:  18%|█▊        | 3102/17714 [00:18<01:12, 200.41it/s]\u001B[A\n",
      "train:  18%|█▊        | 3146/17714 [00:19<01:13, 197.11it/s]\u001B[A\n",
      "train:  18%|█▊        | 3190/17714 [00:19<01:16, 189.96it/s]\u001B[A\n",
      "train:  18%|█▊        | 3234/17714 [00:19<01:13, 197.35it/s]\u001B[A\n",
      "train:  19%|█▊        | 3278/17714 [00:19<01:16, 189.20it/s]\u001B[A\n",
      "train:  19%|█▉        | 3322/17714 [00:20<01:13, 195.78it/s]\u001B[A\n",
      "train:  19%|█▉        | 3366/17714 [00:20<01:16, 187.50it/s]\u001B[A\n",
      "train:  19%|█▉        | 3410/17714 [00:20<01:19, 180.04it/s]\u001B[A\n",
      "train:  19%|█▉        | 3454/17714 [00:20<01:20, 177.28it/s]\u001B[A\n",
      "train:  20%|█▉        | 3498/17714 [00:21<01:17, 183.38it/s]\u001B[A\n",
      "train:  20%|█▉        | 3542/17714 [00:21<01:15, 187.73it/s]\u001B[A\n",
      "train:  20%|██        | 3586/17714 [00:21<01:17, 183.19it/s]\u001B[A\n",
      "train:  20%|██        | 3630/17714 [00:21<01:15, 185.40it/s]\u001B[A\n",
      "train:  21%|██        | 3674/17714 [00:21<01:12, 192.66it/s]\u001B[A\n",
      "train:  21%|██        | 3718/17714 [00:22<01:17, 181.05it/s]\u001B[A\n",
      "train:  21%|██        | 3762/17714 [00:22<01:16, 183.32it/s]\u001B[A\n",
      "train:  21%|██▏       | 3806/17714 [00:22<01:13, 189.20it/s]\u001B[A\n",
      "train:  22%|██▏       | 3850/17714 [00:22<01:11, 192.59it/s]\u001B[A\n",
      "train:  22%|██▏       | 3894/17714 [00:23<01:14, 185.26it/s]\u001B[A\n",
      "train:  22%|██▏       | 3938/17714 [00:23<01:13, 186.90it/s]\u001B[A\n",
      "train:  22%|██▏       | 3982/17714 [00:23<01:14, 184.01it/s]\u001B[A\n",
      "train:  23%|██▎       | 4026/17714 [00:23<01:14, 183.47it/s]\u001B[A\n",
      "train:  23%|██▎       | 4070/17714 [00:24<01:11, 189.82it/s]\u001B[A\n",
      "train:  23%|██▎       | 4114/17714 [00:24<01:14, 181.50it/s]\u001B[A\n",
      "train:  23%|██▎       | 4158/17714 [00:24<01:13, 185.27it/s]\u001B[A\n",
      "train:  24%|██▎       | 4202/17714 [00:24<01:10, 191.13it/s]\u001B[A\n",
      "train:  24%|██▍       | 4246/17714 [00:25<01:15, 178.04it/s]\u001B[A\n",
      "train:  24%|██▍       | 4290/17714 [00:25<01:14, 180.94it/s]\u001B[A\n",
      "train:  24%|██▍       | 4334/17714 [00:25<01:11, 188.20it/s]\u001B[A\n",
      "train:  25%|██▍       | 4378/17714 [00:25<01:10, 188.48it/s]\u001B[A\n",
      "train:  25%|██▍       | 4422/17714 [00:26<01:12, 183.62it/s]\u001B[A\n",
      "train:  25%|██▌       | 4466/17714 [00:26<01:13, 179.62it/s]\u001B[A\n",
      "train:  25%|██▌       | 4510/17714 [00:26<01:15, 173.88it/s]\u001B[A\n",
      "train:  26%|██▌       | 4554/17714 [00:26<01:08, 191.82it/s]\u001B[A\n",
      "train:  26%|██▌       | 4598/17714 [00:27<01:12, 182.04it/s]\u001B[A\n",
      "train:  26%|██▌       | 4642/17714 [00:27<01:13, 176.81it/s]\u001B[A\n",
      "train:  26%|██▋       | 4686/17714 [00:27<01:14, 175.33it/s]\u001B[A\n",
      "train:  27%|██▋       | 4730/17714 [00:27<01:19, 163.52it/s]\u001B[A\n",
      "train:  27%|██▋       | 4774/17714 [00:28<01:17, 166.31it/s]\u001B[A\n",
      "train:  27%|██▋       | 4818/17714 [00:28<01:13, 174.66it/s]\u001B[A\n",
      "train:  27%|██▋       | 4862/17714 [00:28<01:14, 172.21it/s]\u001B[A\n",
      "train:  28%|██▊       | 4906/17714 [00:28<01:12, 177.86it/s]\u001B[A\n",
      "train:  28%|██▊       | 4950/17714 [00:29<01:11, 177.54it/s]\u001B[A\n",
      "train:  28%|██▊       | 4994/17714 [00:29<01:11, 177.96it/s]\u001B[A\n",
      "train:  28%|██▊       | 5038/17714 [00:29<01:15, 167.77it/s]\u001B[A\n",
      "train:  29%|██▊       | 5082/17714 [00:29<01:12, 173.75it/s]\u001B[A\n",
      "train:  29%|██▉       | 5126/17714 [00:30<01:08, 182.60it/s]\u001B[A\n",
      "train:  29%|██▉       | 5170/17714 [00:30<01:13, 171.60it/s]\u001B[A\n",
      "train:  29%|██▉       | 5214/17714 [00:30<01:09, 178.74it/s]\u001B[A\n",
      "train:  30%|██▉       | 5258/17714 [00:30<01:10, 175.45it/s]\u001B[A\n",
      "train:  30%|██▉       | 5302/17714 [00:31<01:12, 171.32it/s]\u001B[A\n",
      "train:  30%|███       | 5346/17714 [00:31<01:10, 174.23it/s]\u001B[A\n",
      "train:  30%|███       | 5390/17714 [00:31<01:12, 169.43it/s]\u001B[A\n",
      "train:  31%|███       | 5434/17714 [00:31<01:12, 168.44it/s]\u001B[A\n",
      "train:  31%|███       | 5478/17714 [00:32<01:13, 167.21it/s]\u001B[A\n",
      "train:  31%|███       | 5522/17714 [00:32<01:16, 159.24it/s]\u001B[A\n",
      "train:  31%|███▏      | 5566/17714 [00:32<01:16, 158.07it/s]\u001B[A\n",
      "train:  32%|███▏      | 5610/17714 [00:33<01:15, 161.02it/s]\u001B[A\n",
      "train:  32%|███▏      | 5654/17714 [00:33<01:16, 156.81it/s]\u001B[A\n",
      "train:  32%|███▏      | 5698/17714 [00:33<01:18, 153.61it/s]\u001B[A\n",
      "train:  32%|███▏      | 5742/17714 [00:33<01:18, 151.83it/s]\u001B[A\n",
      "train:  33%|███▎      | 5786/17714 [00:34<01:14, 160.30it/s]\u001B[A\n",
      "train:  33%|███▎      | 5830/17714 [00:34<01:19, 149.13it/s]\u001B[A\n",
      "train:  33%|███▎      | 5874/17714 [00:34<01:17, 151.96it/s]\u001B[A\n",
      "train:  33%|███▎      | 5918/17714 [00:35<01:12, 163.50it/s]\u001B[A\n",
      "train:  34%|███▎      | 5962/17714 [00:35<01:13, 160.23it/s]\u001B[A\n",
      "train:  34%|███▍      | 6006/17714 [00:35<01:12, 161.50it/s]\u001B[A\n",
      "train:  34%|███▍      | 6050/17714 [00:35<01:10, 164.31it/s]\u001B[A\n",
      "train:  34%|███▍      | 6094/17714 [00:36<01:13, 158.24it/s]\u001B[A\n",
      "train:  35%|███▍      | 6138/17714 [00:36<01:14, 155.88it/s]\u001B[A\n",
      "train:  35%|███▍      | 6182/17714 [00:36<01:13, 157.30it/s]\u001B[A\n",
      "train:  35%|███▌      | 6226/17714 [00:36<01:11, 160.01it/s]\u001B[A\n",
      "train:  35%|███▌      | 6270/17714 [00:37<01:12, 157.49it/s]\u001B[A\n",
      "train:  36%|███▌      | 6314/17714 [00:37<01:13, 155.10it/s]\u001B[A\n",
      "train:  36%|███▌      | 6358/17714 [00:37<01:11, 157.83it/s]\u001B[A\n",
      "train:  36%|███▌      | 6402/17714 [00:38<01:12, 155.28it/s]\u001B[A\n",
      "train:  36%|███▋      | 6446/17714 [00:38<01:15, 149.97it/s]\u001B[A\n",
      "train:  37%|███▋      | 6490/17714 [00:38<01:23, 134.93it/s]\u001B[A\n",
      "train:  37%|███▋      | 6534/17714 [00:39<01:17, 143.78it/s]\u001B[A\n",
      "train:  37%|███▋      | 6578/17714 [00:39<01:14, 148.94it/s]\u001B[A\n",
      "train:  37%|███▋      | 6622/17714 [00:39<01:13, 151.69it/s]\u001B[A\n",
      "train:  38%|███▊      | 6666/17714 [00:39<01:14, 148.66it/s]\u001B[A\n",
      "train:  38%|███▊      | 6710/17714 [00:40<01:20, 136.12it/s]\u001B[A\n",
      "train:  38%|███▊      | 6754/17714 [00:40<01:19, 137.98it/s]\u001B[A\n",
      "train:  38%|███▊      | 6798/17714 [00:40<01:15, 144.05it/s]\u001B[A\n",
      "train:  39%|███▊      | 6842/17714 [00:41<01:13, 147.21it/s]\u001B[A\n",
      "train:  39%|███▉      | 6886/17714 [00:41<01:12, 149.80it/s]\u001B[A\n",
      "train:  39%|███▉      | 6930/17714 [00:41<01:10, 152.37it/s]\u001B[A\n",
      "train:  39%|███▉      | 6974/17714 [00:42<01:06, 160.48it/s]\u001B[A\n",
      "train:  40%|███▉      | 7018/17714 [00:42<01:05, 162.11it/s]\u001B[A\n",
      "train:  40%|███▉      | 7062/17714 [00:42<01:09, 154.34it/s]\u001B[A\n",
      "train:  40%|████      | 7106/17714 [00:42<01:06, 158.64it/s]\u001B[A\n",
      "train:  40%|████      | 7150/17714 [00:43<01:05, 160.36it/s]\u001B[A\n",
      "train:  41%|████      | 7194/17714 [00:43<01:02, 169.19it/s]\u001B[A\n",
      "train:  41%|████      | 7238/17714 [00:43<01:09, 150.74it/s]\u001B[A\n",
      "train:  41%|████      | 7282/17714 [00:43<01:06, 157.42it/s]\u001B[A\n",
      "train:  41%|████▏     | 7326/17714 [00:44<01:02, 166.79it/s]\u001B[A\n",
      "train:  42%|████▏     | 7370/17714 [00:44<00:59, 174.99it/s]\u001B[A\n",
      "train:  42%|████▏     | 7414/17714 [00:44<00:57, 180.19it/s]\u001B[A\n",
      "train:  42%|████▏     | 7458/17714 [00:44<00:58, 174.76it/s]\u001B[A\n",
      "train:  42%|████▏     | 7502/17714 [00:45<00:57, 176.79it/s]\u001B[A\n",
      "train:  43%|████▎     | 7546/17714 [00:45<00:58, 174.82it/s]\u001B[A\n",
      "train:  43%|████▎     | 7590/17714 [00:45<00:56, 177.64it/s]\u001B[A\n",
      "train:  43%|████▎     | 7634/17714 [00:45<00:54, 185.10it/s]\u001B[A\n",
      "train:  43%|████▎     | 7678/17714 [00:46<00:53, 188.60it/s]\u001B[A\n",
      "train:  44%|████▎     | 7722/17714 [00:46<00:54, 183.38it/s]\u001B[A\n",
      "train:  44%|████▍     | 7766/17714 [00:46<00:52, 189.10it/s]\u001B[A\n",
      "train:  44%|████▍     | 7810/17714 [00:46<00:54, 183.09it/s]\u001B[A\n",
      "train:  44%|████▍     | 7854/17714 [00:47<00:56, 175.16it/s]\u001B[A\n",
      "train:  45%|████▍     | 7898/17714 [00:47<00:56, 174.88it/s]\u001B[A\n",
      "train:  45%|████▍     | 7942/17714 [00:47<00:55, 175.78it/s]\u001B[A\n",
      "train:  45%|████▌     | 7986/17714 [00:47<00:56, 172.63it/s]\u001B[A\n",
      "train:  45%|████▌     | 8030/17714 [00:48<00:55, 175.91it/s]\u001B[A\n",
      "train:  46%|████▌     | 8074/17714 [00:48<00:56, 170.25it/s]\u001B[A\n",
      "train:  46%|████▌     | 8118/17714 [00:48<00:58, 164.00it/s]\u001B[A\n",
      "train:  46%|████▌     | 8162/17714 [00:48<00:54, 175.19it/s]\u001B[A\n",
      "train:  46%|████▋     | 8206/17714 [00:49<00:55, 172.10it/s]\u001B[A\n",
      "train:  47%|████▋     | 8250/17714 [00:49<00:53, 176.18it/s]\u001B[A\n",
      "train:  47%|████▋     | 8294/17714 [00:49<00:50, 187.38it/s]\u001B[A\n",
      "train:  47%|████▋     | 8338/17714 [00:49<00:50, 187.15it/s]\u001B[A\n",
      "train:  47%|████▋     | 8382/17714 [00:50<00:49, 188.32it/s]\u001B[A\n",
      "train:  48%|████▊     | 8426/17714 [00:50<00:48, 192.92it/s]\u001B[A\n",
      "train:  48%|████▊     | 8470/17714 [00:50<00:50, 184.32it/s]\u001B[A\n",
      "train:  48%|████▊     | 8514/17714 [00:50<00:48, 189.59it/s]\u001B[A\n",
      "train:  48%|████▊     | 8558/17714 [00:50<00:47, 193.68it/s]\u001B[A\n",
      "train:  49%|████▊     | 8602/17714 [00:51<00:46, 194.49it/s]\u001B[A\n",
      "train:  49%|████▉     | 8646/17714 [00:51<00:45, 199.42it/s]\u001B[A\n",
      "train:  49%|████▉     | 8690/17714 [00:51<00:45, 197.11it/s]\u001B[A\n",
      "train:  49%|████▉     | 8734/17714 [00:51<00:44, 202.80it/s]\u001B[A\n",
      "train:  50%|████▉     | 8778/17714 [00:51<00:42, 209.11it/s]\u001B[A\n",
      "train:  50%|████▉     | 8822/17714 [00:52<00:40, 218.94it/s]\u001B[A\n",
      "train:  50%|█████     | 8866/17714 [00:52<00:40, 217.45it/s]\u001B[A\n",
      "train:  50%|█████     | 8910/17714 [00:52<00:41, 214.38it/s]\u001B[A\n",
      "train:  51%|█████     | 8954/17714 [00:52<00:41, 210.43it/s]\u001B[A\n",
      "train:  51%|█████     | 8998/17714 [00:53<00:42, 204.86it/s]\u001B[A\n",
      "train:  51%|█████     | 9042/17714 [00:53<00:43, 199.27it/s]\u001B[A\n",
      "train:  51%|█████▏    | 9086/17714 [00:53<00:43, 196.55it/s]\u001B[A\n",
      "train:  52%|█████▏    | 9130/17714 [00:53<00:42, 200.83it/s]\u001B[A\n",
      "train:  52%|█████▏    | 9174/17714 [00:53<00:40, 208.36it/s]\u001B[A\n",
      "train:  52%|█████▏    | 9218/17714 [00:54<00:42, 201.22it/s]\u001B[A\n",
      "train:  52%|█████▏    | 9262/17714 [00:54<00:44, 189.24it/s]\u001B[A\n",
      "train:  53%|█████▎    | 9306/17714 [00:54<00:45, 184.20it/s]\u001B[A\n",
      "train:  53%|█████▎    | 9350/17714 [00:54<00:44, 187.79it/s]\u001B[A\n",
      "train:  53%|█████▎    | 9394/17714 [00:55<00:45, 183.80it/s]\u001B[A\n",
      "train:  53%|█████▎    | 9438/17714 [00:55<00:45, 180.41it/s]\u001B[A\n",
      "train:  54%|█████▎    | 9482/17714 [00:55<00:45, 180.98it/s]\u001B[A\n",
      "train:  54%|█████▍    | 9526/17714 [00:55<00:44, 183.38it/s]\u001B[A\n",
      "train:  54%|█████▍    | 9570/17714 [00:56<00:45, 178.20it/s]\u001B[A\n",
      "train:  54%|█████▍    | 9614/17714 [00:56<00:44, 181.36it/s]\u001B[A\n",
      "train:  55%|█████▍    | 9658/17714 [00:56<00:46, 175.12it/s]\u001B[A\n",
      "train:  55%|█████▍    | 9702/17714 [00:56<00:47, 169.62it/s]\u001B[A\n",
      "train:  55%|█████▌    | 9746/17714 [00:57<00:46, 172.46it/s]\u001B[A\n",
      "train:  55%|█████▌    | 9790/17714 [00:57<00:45, 173.43it/s]\u001B[A\n",
      "train:  56%|█████▌    | 9834/17714 [00:57<00:44, 177.47it/s]\u001B[A\n",
      "train:  56%|█████▌    | 9878/17714 [00:57<00:43, 180.35it/s]\u001B[A\n",
      "train:  56%|█████▌    | 9922/17714 [00:58<00:40, 193.49it/s]\u001B[A\n",
      "train:  56%|█████▋    | 9966/17714 [00:58<00:40, 189.78it/s]\u001B[A\n",
      "train:  57%|█████▋    | 10010/17714 [00:58<00:40, 188.32it/s]\u001B[A\n",
      "train:  57%|█████▋    | 10054/17714 [00:58<00:39, 195.21it/s]\u001B[A\n",
      "train:  57%|█████▋    | 10098/17714 [00:58<00:39, 195.27it/s]\u001B[A\n",
      "train:  57%|█████▋    | 10142/17714 [00:59<00:37, 203.47it/s]\u001B[A\n",
      "train:  58%|█████▊    | 10186/17714 [00:59<00:37, 200.23it/s]\u001B[A\n",
      "train:  58%|█████▊    | 10230/17714 [00:59<00:37, 199.80it/s]\u001B[A\n",
      "train:  58%|█████▊    | 10274/17714 [00:59<00:37, 196.42it/s]\u001B[A\n",
      "train:  58%|█████▊    | 10318/17714 [01:00<00:39, 189.32it/s]\u001B[A\n",
      "train:  58%|█████▊    | 10362/17714 [01:00<00:36, 203.79it/s]\u001B[A\n",
      "train:  59%|█████▊    | 10406/17714 [01:00<00:37, 193.38it/s]\u001B[A\n",
      "train:  59%|█████▉    | 10450/17714 [01:00<00:41, 174.12it/s]\u001B[A\n",
      "train:  59%|█████▉    | 10494/17714 [01:01<00:41, 172.63it/s]\u001B[A\n",
      "train:  59%|█████▉    | 10538/17714 [01:01<00:39, 181.79it/s]\u001B[A\n",
      "train:  60%|█████▉    | 10582/17714 [01:01<00:38, 186.53it/s]\u001B[A\n",
      "train:  60%|█████▉    | 10626/17714 [01:01<00:38, 186.06it/s]\u001B[A\n",
      "train:  60%|██████    | 10670/17714 [01:01<00:37, 189.24it/s]\u001B[A\n",
      "train:  60%|██████    | 10714/17714 [01:02<00:36, 191.10it/s]\u001B[A\n",
      "train:  61%|██████    | 10758/17714 [01:02<00:36, 191.37it/s]\u001B[A\n",
      "train:  61%|██████    | 10802/17714 [01:02<00:37, 185.78it/s]\u001B[A\n",
      "train:  61%|██████    | 10846/17714 [01:02<00:36, 189.14it/s]\u001B[A\n",
      "train:  61%|██████▏   | 10890/17714 [01:03<00:35, 190.49it/s]\u001B[A\n",
      "train:  62%|██████▏   | 10934/17714 [01:03<00:36, 184.27it/s]\u001B[A\n",
      "train:  62%|██████▏   | 10978/17714 [01:03<00:36, 185.63it/s]\u001B[A\n",
      "train:  62%|██████▏   | 11022/17714 [01:03<00:35, 187.84it/s]\u001B[A\n",
      "train:  62%|██████▏   | 11066/17714 [01:04<00:36, 184.29it/s]\u001B[A\n",
      "train:  63%|██████▎   | 11110/17714 [01:04<00:35, 184.75it/s]\u001B[A\n",
      "train:  63%|██████▎   | 11154/17714 [01:04<00:35, 185.85it/s]\u001B[A\n",
      "train:  63%|██████▎   | 11198/17714 [01:04<00:34, 190.44it/s]\u001B[A\n",
      "train:  63%|██████▎   | 11242/17714 [01:05<00:34, 189.07it/s]\u001B[A\n",
      "train:  64%|██████▎   | 11286/17714 [01:05<00:33, 192.77it/s]\u001B[A\n",
      "train:  64%|██████▍   | 11330/17714 [01:05<00:33, 192.69it/s]\u001B[A\n",
      "train:  64%|██████▍   | 11374/17714 [01:05<00:33, 191.12it/s]\u001B[A\n",
      "train:  64%|██████▍   | 11418/17714 [01:05<00:32, 196.17it/s]\u001B[A\n",
      "train:  65%|██████▍   | 11462/17714 [01:06<00:32, 193.24it/s]\u001B[A\n",
      "train:  65%|██████▍   | 11506/17714 [01:06<00:30, 204.79it/s]\u001B[A\n",
      "train:  65%|██████▌   | 11550/17714 [01:06<00:31, 197.53it/s]\u001B[A\n",
      "train:  65%|██████▌   | 11594/17714 [01:06<00:32, 189.42it/s]\u001B[A\n",
      "train:  66%|██████▌   | 11638/17714 [01:07<00:30, 201.04it/s]\u001B[A\n",
      "train:  66%|██████▌   | 11682/17714 [01:07<00:31, 194.18it/s]\u001B[A\n",
      "train:  66%|██████▌   | 11726/17714 [01:07<00:32, 186.94it/s]\u001B[A\n",
      "train:  66%|██████▋   | 11770/17714 [01:07<00:30, 196.14it/s]\u001B[A\n",
      "train:  67%|██████▋   | 11814/17714 [01:07<00:30, 190.80it/s]\u001B[A\n",
      "train:  67%|██████▋   | 11858/17714 [01:08<00:31, 184.98it/s]\u001B[A\n",
      "train:  67%|██████▋   | 11902/17714 [01:08<00:29, 195.57it/s]\u001B[A\n",
      "train:  67%|██████▋   | 11946/17714 [01:08<00:29, 193.17it/s]\u001B[A\n",
      "train:  68%|██████▊   | 11990/17714 [01:08<00:29, 190.96it/s]\u001B[A\n",
      "train:  68%|██████▊   | 12034/17714 [01:09<00:30, 186.50it/s]\u001B[A\n",
      "train:  68%|██████▊   | 12078/17714 [01:09<00:30, 184.60it/s]\u001B[A\n",
      "train:  68%|██████▊   | 12122/17714 [01:09<00:30, 183.02it/s]\u001B[A\n",
      "train:  69%|██████▊   | 12166/17714 [01:09<00:29, 188.16it/s]\u001B[A\n",
      "train:  69%|██████▉   | 12210/17714 [01:10<00:28, 194.77it/s]\u001B[A\n",
      "train:  69%|██████▉   | 12254/17714 [01:10<00:28, 193.44it/s]\u001B[A\n",
      "train:  69%|██████▉   | 12298/17714 [01:10<00:28, 188.96it/s]\u001B[A\n",
      "train:  70%|██████▉   | 12342/17714 [01:10<00:28, 191.38it/s]\u001B[A\n",
      "train:  70%|██████▉   | 12386/17714 [01:10<00:28, 186.78it/s]\u001B[A\n",
      "train:  70%|███████   | 12430/17714 [01:11<00:27, 193.80it/s]\u001B[A\n",
      "train:  70%|███████   | 12474/17714 [01:11<00:27, 190.97it/s]\u001B[A\n",
      "train:  71%|███████   | 12518/17714 [01:11<00:27, 191.30it/s]\u001B[A\n",
      "train:  71%|███████   | 12562/17714 [01:11<00:27, 189.30it/s]\u001B[A\n",
      "train:  71%|███████   | 12606/17714 [01:12<00:26, 190.47it/s]\u001B[A\n",
      "train:  71%|███████▏  | 12650/17714 [01:12<00:26, 190.43it/s]\u001B[A\n",
      "train:  72%|███████▏  | 12694/17714 [01:12<00:26, 191.94it/s]\u001B[A\n",
      "train:  72%|███████▏  | 12738/17714 [01:12<00:26, 185.12it/s]\u001B[A\n",
      "train:  72%|███████▏  | 12782/17714 [01:13<00:26, 187.34it/s]\u001B[A\n",
      "train:  72%|███████▏  | 12826/17714 [01:13<00:26, 186.89it/s]\u001B[A\n",
      "train:  73%|███████▎  | 12870/17714 [01:13<00:27, 175.48it/s]\u001B[A\n",
      "train:  73%|███████▎  | 12914/17714 [01:13<00:26, 181.06it/s]\u001B[A\n",
      "train:  73%|███████▎  | 12958/17714 [01:14<00:26, 176.28it/s]\u001B[A\n",
      "train:  73%|███████▎  | 13002/17714 [01:14<00:26, 176.29it/s]\u001B[A\n",
      "train:  74%|███████▎  | 13046/17714 [01:14<00:26, 178.23it/s]\u001B[A\n",
      "train:  74%|███████▍  | 13090/17714 [01:14<00:25, 180.34it/s]\u001B[A\n",
      "train:  74%|███████▍  | 13134/17714 [01:15<00:23, 191.93it/s]\u001B[A\n",
      "train:  74%|███████▍  | 13178/17714 [01:15<00:23, 194.42it/s]\u001B[A\n",
      "train:  75%|███████▍  | 13222/17714 [01:15<00:22, 197.05it/s]\u001B[A\n",
      "train:  75%|███████▍  | 13266/17714 [01:15<00:22, 200.69it/s]\u001B[A\n",
      "train:  75%|███████▌  | 13310/17714 [01:15<00:21, 202.20it/s]\u001B[A\n",
      "train:  75%|███████▌  | 13354/17714 [01:16<00:20, 215.60it/s]\u001B[A\n",
      "train:  76%|███████▌  | 13398/17714 [01:16<00:20, 213.96it/s]\u001B[A\n",
      "train:  76%|███████▌  | 13442/17714 [01:16<00:22, 193.54it/s]\u001B[A\n",
      "train:  76%|███████▌  | 13486/17714 [01:16<00:21, 192.29it/s]\u001B[A\n",
      "train:  76%|███████▋  | 13530/17714 [01:16<00:21, 194.93it/s]\u001B[A\n",
      "train:  77%|███████▋  | 13574/17714 [01:17<00:21, 191.33it/s]\u001B[A\n",
      "train:  77%|███████▋  | 13618/17714 [01:17<00:22, 184.63it/s]\u001B[A\n",
      "train:  77%|███████▋  | 13662/17714 [01:17<00:21, 191.51it/s]\u001B[A\n",
      "train:  77%|███████▋  | 13706/17714 [01:17<00:21, 188.57it/s]\u001B[A\n",
      "train:  78%|███████▊  | 13750/17714 [01:18<00:20, 196.10it/s]\u001B[A\n",
      "train:  78%|███████▊  | 13794/17714 [01:18<00:20, 186.82it/s]\u001B[A\n",
      "train:  78%|███████▊  | 13838/17714 [01:18<00:20, 192.80it/s]\u001B[A\n",
      "train:  78%|███████▊  | 13882/17714 [01:18<00:19, 197.69it/s]\u001B[A\n",
      "train:  79%|███████▊  | 13926/17714 [01:19<00:18, 205.96it/s]\u001B[A\n",
      "train:  79%|███████▉  | 13970/17714 [01:19<00:18, 198.38it/s]\u001B[A\n",
      "train:  79%|███████▉  | 14014/17714 [01:19<00:18, 195.35it/s]\u001B[A\n",
      "train:  79%|███████▉  | 14058/17714 [01:19<00:18, 196.02it/s]\u001B[A\n",
      "train:  80%|███████▉  | 14102/17714 [01:19<00:18, 197.15it/s]\u001B[A\n",
      "train:  80%|███████▉  | 14146/17714 [01:20<00:19, 181.87it/s]\u001B[A\n",
      "train:  80%|████████  | 14190/17714 [01:20<00:21, 162.38it/s]\u001B[A\n",
      "train:  80%|████████  | 14234/17714 [01:20<00:21, 161.49it/s]\u001B[A\n",
      "train:  81%|████████  | 14278/17714 [01:21<00:21, 163.37it/s]\u001B[A\n",
      "train:  81%|████████  | 14322/17714 [01:21<00:19, 169.96it/s]\u001B[A\n",
      "train:  81%|████████  | 14366/17714 [01:21<00:20, 163.35it/s]\u001B[A\n",
      "train:  81%|████████▏ | 14410/17714 [01:21<00:19, 168.55it/s]\u001B[A\n",
      "train:  82%|████████▏ | 14454/17714 [01:22<00:20, 160.07it/s]\u001B[A\n",
      "train:  82%|████████▏ | 14498/17714 [01:22<00:18, 174.25it/s]\u001B[A\n",
      "train:  82%|████████▏ | 14542/17714 [01:22<00:18, 172.71it/s]\u001B[A\n",
      "train:  82%|████████▏ | 14586/17714 [01:22<00:17, 182.65it/s]\u001B[A\n",
      "train:  83%|████████▎ | 14630/17714 [01:23<00:16, 189.62it/s]\u001B[A\n",
      "train:  83%|████████▎ | 14674/17714 [01:23<00:15, 194.07it/s]\u001B[A\n",
      "train:  83%|████████▎ | 14718/17714 [01:23<00:15, 197.64it/s]\u001B[A\n",
      "train:  83%|████████▎ | 14762/17714 [01:23<00:14, 203.25it/s]\u001B[A\n",
      "train:  84%|████████▎ | 14806/17714 [01:23<00:14, 194.16it/s]\u001B[A\n",
      "train:  84%|████████▍ | 14850/17714 [01:24<00:15, 185.23it/s]\u001B[A\n",
      "train:  84%|████████▍ | 14894/17714 [01:24<00:16, 171.64it/s]\u001B[A\n",
      "train:  84%|████████▍ | 14938/17714 [01:24<00:16, 167.41it/s]\u001B[A\n",
      "train:  85%|████████▍ | 14982/17714 [01:25<00:16, 161.99it/s]\u001B[A\n",
      "train:  85%|████████▍ | 15026/17714 [01:25<00:16, 160.74it/s]\u001B[A\n",
      "train:  85%|████████▌ | 15070/17714 [01:25<00:16, 163.55it/s]\u001B[A\n",
      "train:  85%|████████▌ | 15114/17714 [01:25<00:16, 158.95it/s]\u001B[A\n",
      "train:  86%|████████▌ | 15158/17714 [01:26<00:14, 171.36it/s]\u001B[A\n",
      "train:  86%|████████▌ | 15202/17714 [01:26<00:13, 183.94it/s]\u001B[A\n",
      "train:  86%|████████▌ | 15246/17714 [01:26<00:13, 187.45it/s]\u001B[A\n",
      "train:  86%|████████▋ | 15290/17714 [01:26<00:12, 201.61it/s]\u001B[A\n",
      "train:  87%|████████▋ | 15334/17714 [01:26<00:11, 198.93it/s]\u001B[A\n",
      "train:  87%|████████▋ | 15378/17714 [01:27<00:11, 204.13it/s]\u001B[A\n",
      "train:  87%|████████▋ | 15422/17714 [01:27<00:10, 216.99it/s]\u001B[A\n",
      "train:  87%|████████▋ | 15466/17714 [01:27<00:10, 208.06it/s]\u001B[A\n",
      "train:  88%|████████▊ | 15510/17714 [01:27<00:10, 219.17it/s]\u001B[A\n",
      "train:  88%|████████▊ | 15554/17714 [01:27<00:10, 214.25it/s]\u001B[A\n",
      "train:  88%|████████▊ | 15598/17714 [01:28<00:09, 216.19it/s]\u001B[A\n",
      "train:  88%|████████▊ | 15642/17714 [01:28<00:10, 200.48it/s]\u001B[A\n",
      "train:  89%|████████▊ | 15686/17714 [01:28<00:11, 180.47it/s]\u001B[A\n",
      "train:  89%|████████▉ | 15730/17714 [01:28<00:11, 171.07it/s]\u001B[A\n",
      "train:  89%|████████▉ | 15774/17714 [01:29<00:11, 162.28it/s]\u001B[A\n",
      "train:  89%|████████▉ | 15818/17714 [01:29<00:11, 158.81it/s]\u001B[A\n",
      "train:  90%|████████▉ | 15862/17714 [01:29<00:11, 160.34it/s]\u001B[A\n",
      "train:  90%|████████▉ | 15906/17714 [01:30<00:11, 154.47it/s]\u001B[A\n",
      "train:  90%|█████████ | 15950/17714 [01:30<00:11, 156.04it/s]\u001B[A\n",
      "train:  90%|█████████ | 15994/17714 [01:30<00:11, 151.04it/s]\u001B[A\n",
      "train:  91%|█████████ | 16038/17714 [01:31<00:10, 152.77it/s]\u001B[A\n",
      "train:  91%|█████████ | 16082/17714 [01:31<00:10, 154.26it/s]\u001B[A\n",
      "train:  91%|█████████ | 16126/17714 [01:31<00:10, 151.70it/s]\u001B[A\n",
      "train:  91%|█████████▏| 16170/17714 [01:31<00:09, 156.43it/s]\u001B[A\n",
      "train:  91%|█████████▏| 16170/17714 [01:42<00:09, 156.43it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16214/17714 [02:01<05:10,  4.82it/s] \u001B[A\n",
      "train:  92%|█████████▏| 16236/17714 [02:12<06:26,  3.83it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16258/17714 [02:24<07:34,  3.20it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16280/17714 [02:30<07:21,  3.25it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16302/17714 [02:37<07:11,  3.27it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16324/17714 [02:44<07:12,  3.21it/s]\u001B[AC:\\Users\\Azzam\\PycharmProjects\\FeatureExtractor1\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "\n",
      "train:  92%|█████████▏| 16346/17714 [02:53<07:39,  2.98it/s]\u001B[A\n",
      "train:  92%|█████████▏| 16368/17714 [02:59<07:07,  3.15it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16390/17714 [03:05<06:52,  3.21it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16412/17714 [03:16<07:51,  2.76it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16434/17714 [03:25<08:02,  2.65it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16456/17714 [03:32<07:32,  2.78it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16478/17714 [03:44<08:24,  2.45it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16500/17714 [03:50<07:25,  2.72it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16522/17714 [03:57<07:14,  2.75it/s]\u001B[A\n",
      "train:  93%|█████████▎| 16544/17714 [04:04<06:50,  2.85it/s]\u001B[A\n",
      "train:  94%|█████████▎| 16566/17714 [04:13<06:54,  2.77it/s]\u001B[A\n",
      "train:  94%|█████████▎| 16588/17714 [04:20<06:26,  2.92it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16610/17714 [04:28<06:35,  2.79it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16632/17714 [04:36<06:19,  2.85it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16654/17714 [04:43<06:09,  2.87it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16676/17714 [04:51<06:06,  2.83it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16698/17714 [04:58<05:52,  2.88it/s]\u001B[A\n",
      "train:  94%|█████████▍| 16720/17714 [05:06<05:46,  2.87it/s]\u001B[A\n",
      "train:  95%|█████████▍| 16742/17714 [05:13<05:29,  2.95it/s]\u001B[A\n",
      "train:  95%|█████████▍| 16764/17714 [05:22<05:35,  2.83it/s]\u001B[A\n",
      "train:  95%|█████████▍| 16786/17714 [05:28<05:15,  2.94it/s]\u001B[A\n",
      "train:  95%|█████████▍| 16808/17714 [05:36<05:12,  2.90it/s]\u001B[A\n",
      "train:  95%|█████████▌| 16830/17714 [05:43<04:58,  2.96it/s]\u001B[A\n",
      "train:  95%|█████████▌| 16852/17714 [05:51<04:55,  2.92it/s]\u001B[A\n",
      "train:  95%|█████████▌| 16874/17714 [06:01<05:14,  2.67it/s]\u001B[A\n",
      "train:  95%|█████████▌| 16896/17714 [06:07<04:46,  2.86it/s]\u001B[A\n",
      "train:  96%|█████████▌| 16918/17714 [06:15<04:34,  2.90it/s]\u001B[A\n",
      "train:  96%|█████████▌| 16940/17714 [06:22<04:28,  2.88it/s]\u001B[A\n",
      "train:  96%|█████████▌| 16962/17714 [06:31<04:27,  2.81it/s]\u001B[A\n",
      "train:  96%|█████████▌| 16984/17714 [06:39<04:19,  2.81it/s]\u001B[A\n",
      "train:  96%|█████████▌| 17006/17714 [06:47<04:13,  2.80it/s]\u001B[A\n",
      "train:  96%|█████████▌| 17028/17714 [06:53<03:55,  2.92it/s]\u001B[A\n",
      "train:  96%|█████████▋| 17050/17714 [07:01<03:51,  2.87it/s]\u001B[A\n",
      "train:  96%|█████████▋| 17072/17714 [07:08<03:38,  2.93it/s]\u001B[A\n",
      "train:  96%|█████████▋| 17094/17714 [07:19<04:00,  2.58it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17116/17714 [07:26<03:40,  2.71it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17138/17714 [07:34<03:25,  2.80it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17160/17714 [07:41<03:17,  2.81it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17182/17714 [07:50<03:12,  2.76it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17204/17714 [07:57<03:00,  2.83it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17226/17714 [08:05<02:51,  2.85it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17248/17714 [08:14<02:50,  2.73it/s]\u001B[A\n",
      "train:  97%|█████████▋| 17270/17714 [08:19<02:25,  3.05it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17292/17714 [08:30<02:38,  2.66it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17314/17714 [08:37<02:27,  2.70it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17336/17714 [08:45<02:16,  2.77it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17358/17714 [08:52<02:05,  2.83it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17380/17714 [08:59<01:55,  2.89it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17402/17714 [09:07<01:47,  2.90it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17424/17714 [09:15<01:41,  2.86it/s]\u001B[A\n",
      "train:  98%|█████████▊| 17446/17714 [09:22<01:32,  2.91it/s]\u001B[A\n",
      "train:  99%|█████████▊| 17468/17714 [09:29<01:21,  3.02it/s]\u001B[A\n",
      "train:  99%|█████████▊| 17490/17714 [09:38<01:20,  2.79it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17512/17714 [09:45<01:10,  2.88it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17534/17714 [09:53<01:03,  2.85it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17556/17714 [10:01<00:55,  2.86it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17578/17714 [10:07<00:45,  2.96it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17600/17714 [10:15<00:38,  3.00it/s]\u001B[A\n",
      "train:  99%|█████████▉| 17622/17714 [10:22<00:30,  2.99it/s]\u001B[A\n",
      "train: 100%|█████████▉| 17644/17714 [10:30<00:23,  2.93it/s]\u001B[A\n",
      "train: 100%|█████████▉| 17666/17714 [10:38<00:16,  2.89it/s]\u001B[A\n",
      "train: 100%|█████████▉| 17688/17714 [10:46<00:09,  2.81it/s]\u001B[A\n",
      "train: 100%|██████████| 17714/17714 [10:54<00:00, 27.08it/s]\u001B[A\n",
      "\n",
      "val:   0%|          | 0/2023 [00:00<?, ?it/s]\u001B[A\n",
      "val:   2%|▏         | 44/2023 [00:00<00:11, 166.89it/s]\u001B[A\n",
      "val:   3%|▎         | 66/2023 [00:00<00:12, 150.91it/s]\u001B[A\n",
      "val:   4%|▍         | 88/2023 [00:00<00:12, 158.82it/s]\u001B[A\n",
      "val:   5%|▌         | 110/2023 [00:00<00:13, 137.21it/s]\u001B[A\n",
      "val:   7%|▋         | 132/2023 [00:00<00:13, 144.85it/s]\u001B[A\n",
      "val:   8%|▊         | 154/2023 [00:01<00:12, 144.36it/s]\u001B[A\n",
      "val:   9%|▊         | 176/2023 [00:01<00:12, 152.92it/s]\u001B[A\n",
      "val:  10%|▉         | 198/2023 [00:01<00:11, 154.74it/s]\u001B[A\n",
      "val:  11%|█         | 220/2023 [00:01<00:11, 156.16it/s]\u001B[A\n",
      "val:  12%|█▏        | 242/2023 [00:01<00:11, 155.54it/s]\u001B[A\n",
      "val:  13%|█▎        | 264/2023 [00:01<00:11, 157.35it/s]\u001B[A\n",
      "val:  14%|█▍        | 286/2023 [00:01<00:11, 156.87it/s]\u001B[A\n",
      "val:  15%|█▌        | 308/2023 [00:02<00:10, 159.34it/s]\u001B[A\n",
      "val:  16%|█▋        | 330/2023 [00:02<00:10, 158.11it/s]\u001B[A\n",
      "val:  17%|█▋        | 352/2023 [00:02<00:10, 157.50it/s]\u001B[A\n",
      "val:  18%|█▊        | 374/2023 [00:02<00:10, 158.27it/s]\u001B[A\n",
      "val:  20%|█▉        | 396/2023 [00:02<00:09, 164.78it/s]\u001B[A\n",
      "val:  21%|██        | 418/2023 [00:02<00:09, 169.51it/s]\u001B[A\n",
      "val:  22%|██▏       | 440/2023 [00:02<00:09, 164.47it/s]\u001B[A\n",
      "val:  23%|██▎       | 462/2023 [00:02<00:09, 163.32it/s]\u001B[A\n",
      "val:  24%|██▍       | 484/2023 [00:03<00:09, 162.40it/s]\u001B[A\n",
      "val:  25%|██▌       | 506/2023 [00:03<00:09, 163.52it/s]\u001B[A\n",
      "val:  26%|██▌       | 528/2023 [00:03<00:09, 165.53it/s]\u001B[A\n",
      "val:  27%|██▋       | 550/2023 [00:03<00:08, 164.67it/s]\u001B[A\n",
      "val:  28%|██▊       | 572/2023 [00:03<00:09, 155.63it/s]\u001B[A\n",
      "val:  29%|██▉       | 594/2023 [00:03<00:09, 148.78it/s]\u001B[A\n",
      "val:  30%|███       | 616/2023 [00:03<00:09, 146.33it/s]\u001B[A\n",
      "val:  32%|███▏      | 638/2023 [00:04<00:09, 139.54it/s]\u001B[A\n",
      "val:  33%|███▎      | 660/2023 [00:04<00:09, 138.62it/s]\u001B[A\n",
      "val:  34%|███▎      | 682/2023 [00:04<00:09, 138.72it/s]\u001B[A\n",
      "val:  35%|███▍      | 704/2023 [00:04<00:09, 137.80it/s]\u001B[A\n",
      "val:  36%|███▌      | 726/2023 [00:04<00:08, 154.84it/s]\u001B[A\n",
      "val:  37%|███▋      | 748/2023 [00:04<00:09, 138.85it/s]\u001B[A\n",
      "val:  38%|███▊      | 770/2023 [00:05<00:10, 115.82it/s]\u001B[A\n",
      "val:  39%|███▉      | 792/2023 [00:05<00:11, 108.98it/s]\u001B[A\n",
      "val:  40%|████      | 814/2023 [00:05<00:09, 122.02it/s]\u001B[A\n",
      "val:  41%|████▏     | 836/2023 [00:05<00:09, 120.10it/s]\u001B[A\n",
      "val:  42%|████▏     | 858/2023 [00:05<00:09, 126.52it/s]\u001B[A\n",
      "val:  43%|████▎     | 880/2023 [00:06<00:08, 129.81it/s]\u001B[A\n",
      "val:  45%|████▍     | 902/2023 [00:06<00:08, 130.16it/s]\u001B[A\n",
      "val:  46%|████▌     | 924/2023 [00:06<00:08, 134.92it/s]\u001B[A\n",
      "val:  47%|████▋     | 946/2023 [00:06<00:07, 134.76it/s]\u001B[A\n",
      "val:  48%|████▊     | 968/2023 [00:06<00:07, 135.96it/s]\u001B[A\n",
      "val:  49%|████▉     | 990/2023 [00:06<00:07, 140.44it/s]\u001B[A\n",
      "val:  50%|█████     | 1012/2023 [00:06<00:07, 141.61it/s]\u001B[A\n",
      "val:  51%|█████     | 1034/2023 [00:07<00:06, 143.34it/s]\u001B[A\n",
      "val:  52%|█████▏    | 1056/2023 [00:07<00:06, 142.79it/s]\u001B[A\n",
      "val:  53%|█████▎    | 1078/2023 [00:07<00:06, 140.11it/s]\u001B[A\n",
      "val:  54%|█████▍    | 1100/2023 [00:07<00:06, 137.46it/s]\u001B[A\n",
      "val:  55%|█████▌    | 1122/2023 [00:07<00:06, 140.32it/s]\u001B[A\n",
      "val:  57%|█████▋    | 1144/2023 [00:07<00:06, 140.84it/s]\u001B[A\n",
      "val:  58%|█████▊    | 1166/2023 [00:08<00:06, 141.61it/s]\u001B[A\n",
      "val:  59%|█████▊    | 1188/2023 [00:08<00:06, 138.23it/s]\u001B[A\n",
      "val:  60%|█████▉    | 1210/2023 [00:08<00:05, 138.56it/s]\u001B[A\n",
      "val:  61%|██████    | 1232/2023 [00:08<00:05, 139.97it/s]\u001B[A\n",
      "val:  62%|██████▏   | 1254/2023 [00:08<00:05, 137.24it/s]\u001B[A\n",
      "val:  63%|██████▎   | 1276/2023 [00:08<00:05, 140.75it/s]\u001B[A\n",
      "val:  64%|██████▍   | 1298/2023 [00:09<00:04, 150.97it/s]\u001B[A\n",
      "val:  65%|██████▌   | 1320/2023 [00:09<00:05, 138.38it/s]\u001B[A\n",
      "val:  66%|██████▋   | 1342/2023 [00:09<00:04, 140.72it/s]\u001B[A\n",
      "val:  67%|██████▋   | 1364/2023 [00:09<00:04, 137.63it/s]\u001B[A\n",
      "val:  69%|██████▊   | 1386/2023 [00:09<00:04, 137.57it/s]\u001B[A\n",
      "val:  70%|██████▉   | 1408/2023 [00:09<00:04, 135.26it/s]\u001B[A\n",
      "val:  71%|███████   | 1430/2023 [00:09<00:04, 139.07it/s]\u001B[A\n",
      "val:  72%|███████▏  | 1452/2023 [00:10<00:04, 140.77it/s]\u001B[A\n",
      "val:  73%|███████▎  | 1474/2023 [00:10<00:03, 144.62it/s]\u001B[A\n",
      "val:  74%|███████▍  | 1496/2023 [00:10<00:03, 141.95it/s]\u001B[A\n",
      "val:  75%|███████▌  | 1518/2023 [00:10<00:03, 139.16it/s]\u001B[A\n",
      "val:  76%|███████▌  | 1540/2023 [00:10<00:03, 136.03it/s]\u001B[A\n",
      "val:  77%|███████▋  | 1562/2023 [00:10<00:03, 137.50it/s]\u001B[A\n",
      "val:  78%|███████▊  | 1584/2023 [00:11<00:03, 139.68it/s]\u001B[A\n",
      "val:  79%|███████▉  | 1606/2023 [00:11<00:02, 143.05it/s]\u001B[A\n",
      "val:  80%|████████  | 1628/2023 [00:11<00:02, 141.79it/s]\u001B[A\n",
      "val:  82%|████████▏ | 1650/2023 [00:11<00:02, 138.43it/s]\u001B[A\n",
      "val:  83%|████████▎ | 1672/2023 [00:11<00:02, 138.58it/s]\u001B[A\n",
      "val:  84%|████████▎ | 1694/2023 [00:11<00:02, 140.74it/s]\u001B[A\n",
      "val:  85%|████████▍ | 1716/2023 [00:12<00:02, 142.41it/s]\u001B[A\n",
      "val:  86%|████████▌ | 1738/2023 [00:12<00:02, 138.52it/s]\u001B[A\n",
      "val:  87%|████████▋ | 1760/2023 [00:12<00:01, 140.38it/s]\u001B[A\n",
      "val:  88%|████████▊ | 1782/2023 [00:12<00:01, 138.10it/s]\u001B[A\n",
      "val:  89%|████████▉ | 1804/2023 [00:12<00:01, 140.52it/s]\u001B[A\n",
      "val:  90%|█████████ | 1826/2023 [00:12<00:01, 135.30it/s]\u001B[A\n",
      "val:  91%|█████████▏| 1848/2023 [00:12<00:01, 139.25it/s]\u001B[A\n",
      "val:  92%|█████████▏| 1870/2023 [00:13<00:01, 135.86it/s]\u001B[A\n",
      "val:  94%|█████████▎| 1892/2023 [00:13<00:00, 132.09it/s]\u001B[A\n",
      "val:  95%|█████████▍| 1914/2023 [00:13<00:00, 135.15it/s]\u001B[A\n",
      "val:  96%|█████████▌| 1936/2023 [00:13<00:00, 138.92it/s]\u001B[A\n",
      "val:  97%|█████████▋| 1958/2023 [00:13<00:00, 141.29it/s]\u001B[A\n",
      "val:  98%|█████████▊| 1980/2023 [00:13<00:00, 141.47it/s]\u001B[A\n",
      "val: 100%|██████████| 2023/2023 [00:14<00:00, 143.65it/s]\u001B[A\n",
      "\n",
      "test:   0%|          | 0/2394 [00:00<?, ?it/s]\u001B[A\n",
      "test:   4%|▎         | 88/2394 [00:00<00:05, 402.85it/s]\u001B[A\n",
      "test:   6%|▌         | 132/2394 [00:00<00:06, 352.98it/s]\u001B[A\n",
      "test:   7%|▋         | 176/2394 [00:00<00:07, 284.73it/s]\u001B[A\n",
      "test:   9%|▉         | 220/2394 [00:00<00:09, 233.54it/s]\u001B[A\n",
      "test:  11%|█         | 264/2394 [00:01<00:08, 240.23it/s]\u001B[A\n",
      "test:  13%|█▎        | 308/2394 [00:01<00:09, 213.20it/s]\u001B[A\n",
      "test:  15%|█▍        | 352/2394 [00:01<00:10, 201.14it/s]\u001B[A\n",
      "test:  17%|█▋        | 396/2394 [00:01<00:10, 195.39it/s]\u001B[A\n",
      "test:  18%|█▊        | 440/2394 [00:01<00:10, 191.39it/s]\u001B[A\n",
      "test:  20%|██        | 484/2394 [00:02<00:09, 196.13it/s]\u001B[A\n",
      "test:  22%|██▏       | 528/2394 [00:02<00:09, 196.84it/s]\u001B[A\n",
      "test:  24%|██▍       | 572/2394 [00:02<00:09, 196.05it/s]\u001B[A\n",
      "test:  26%|██▌       | 616/2394 [00:02<00:08, 197.57it/s]\u001B[A\n",
      "test:  28%|██▊       | 660/2394 [00:03<00:08, 197.68it/s]\u001B[A\n",
      "test:  29%|██▉       | 704/2394 [00:03<00:08, 199.95it/s]\u001B[A\n",
      "test:  31%|███       | 748/2394 [00:03<00:07, 205.93it/s]\u001B[A\n",
      "test:  33%|███▎      | 792/2394 [00:03<00:07, 201.30it/s]\u001B[A\n",
      "test:  35%|███▍      | 836/2394 [00:03<00:07, 197.15it/s]\u001B[A\n",
      "test:  37%|███▋      | 880/2394 [00:04<00:07, 195.78it/s]\u001B[A\n",
      "test:  39%|███▊      | 924/2394 [00:04<00:07, 198.70it/s]\u001B[A\n",
      "test:  40%|████      | 968/2394 [00:04<00:07, 196.45it/s]\u001B[A\n",
      "test:  42%|████▏     | 1012/2394 [00:04<00:07, 197.01it/s]\u001B[A\n",
      "test:  44%|████▍     | 1056/2394 [00:05<00:06, 200.97it/s]\u001B[A\n",
      "test:  46%|████▌     | 1100/2394 [00:05<00:06, 194.10it/s]\u001B[A\n",
      "test:  48%|████▊     | 1144/2394 [00:05<00:06, 198.95it/s]\u001B[A\n",
      "test:  50%|████▉     | 1188/2394 [00:05<00:06, 196.59it/s]\u001B[A\n",
      "test:  51%|█████▏    | 1232/2394 [00:05<00:06, 189.55it/s]\u001B[A\n",
      "test:  53%|█████▎    | 1276/2394 [00:06<00:05, 201.93it/s]\u001B[A\n",
      "test:  55%|█████▌    | 1320/2394 [00:06<00:05, 199.35it/s]\u001B[A\n",
      "test:  57%|█████▋    | 1364/2394 [00:06<00:05, 200.75it/s]\u001B[A\n",
      "test:  59%|█████▉    | 1408/2394 [00:06<00:04, 197.29it/s]\u001B[A\n",
      "test:  61%|██████    | 1452/2394 [00:07<00:04, 201.95it/s]\u001B[A\n",
      "test:  62%|██████▏   | 1496/2394 [00:07<00:04, 201.52it/s]\u001B[A\n",
      "test:  64%|██████▍   | 1540/2394 [00:07<00:04, 200.90it/s]\u001B[A\n",
      "test:  66%|██████▌   | 1584/2394 [00:07<00:04, 199.16it/s]\u001B[A\n",
      "test:  68%|██████▊   | 1628/2394 [00:07<00:03, 205.72it/s]\u001B[A\n",
      "test:  70%|██████▉   | 1672/2394 [00:08<00:03, 198.64it/s]\u001B[A\n",
      "test:  72%|███████▏  | 1716/2394 [00:08<00:03, 195.11it/s]\u001B[A\n",
      "test:  74%|███████▎  | 1760/2394 [00:08<00:03, 194.01it/s]\u001B[A\n",
      "test:  75%|███████▌  | 1804/2394 [00:08<00:02, 198.44it/s]\u001B[A\n",
      "test:  77%|███████▋  | 1848/2394 [00:09<00:03, 181.44it/s]\u001B[A\n",
      "test:  79%|███████▉  | 1892/2394 [00:09<00:02, 185.57it/s]\u001B[A\n",
      "test:  81%|████████  | 1936/2394 [00:09<00:02, 172.79it/s]\u001B[A\n",
      "test:  83%|████████▎ | 1980/2394 [00:09<00:02, 181.13it/s]\u001B[A\n",
      "test:  85%|████████▍ | 2024/2394 [00:10<00:01, 186.74it/s]\u001B[A\n",
      "test:  86%|████████▋ | 2068/2394 [00:10<00:01, 196.43it/s]\u001B[A\n",
      "test:  88%|████████▊ | 2112/2394 [00:10<00:01, 191.99it/s]\u001B[A\n",
      "test:  90%|█████████ | 2156/2394 [00:10<00:01, 198.14it/s]\u001B[A\n",
      "test:  92%|█████████▏| 2200/2394 [00:10<00:00, 197.22it/s]\u001B[A\n",
      "test:  94%|█████████▎| 2244/2394 [00:11<00:00, 203.03it/s]\u001B[A\n",
      "test:  96%|█████████▌| 2288/2394 [00:11<00:00, 219.85it/s]\u001B[A\n",
      "test:  97%|█████████▋| 2332/2394 [00:11<00:00, 213.98it/s]\u001B[A\n",
      "test: 100%|██████████| 2394/2394 [00:11<00:00, 203.74it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims: (17714, 1584) (2023, 1584) (2394, 1584)\n",
      "classes: ['angry', 'happy', 'neutral', 'sad']\n",
      "NaNs in train: 0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# 1. Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit the scaler ONLY on the training data, to avoid data leakage\n",
    "print(\"\\nFitting scaler on training data...\")\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 3. Save the fitted scaler for deployment/inference\n",
    "#\n",
    "joblib.dump(scaler, 'feature_scaler.joblib')\n",
    "print(\"Scaler saved to 'feature_scaler.joblib'\")\n",
    "\n",
    "# 4. Transform all three datasets using the SAME fitted scaler\n",
    "print(\"Transforming train, val, and test sets...\")\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"New scaled dims:\", X_train_scaled.shape, X_val_scaled.shape, X_test_scaled.shape)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "4Su6uhCOvuGD",
    "ExecuteTime": {
     "end_time": "2025-08-31T00:36:30.382399Z",
     "start_time": "2025-08-31T00:36:30.087448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting scaler on training data...\n",
      "Scaler saved to 'feature_scaler.joblib'\n",
      "Transforming train, val, and test sets...\n",
      "New scaled dims: (17714, 1584) (2023, 1584) (2394, 1584)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T00:36:35.900205Z",
     "start_time": "2025-08-31T00:36:35.741826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Statistics for both raw and scaled features\n",
    "def print_stats(name, X):\n",
    "    print(f\"\\nStats for {name}:\")\n",
    "    print(\"  Max:\", np.max(X))\n",
    "    print(\"  Min:\", np.min(X))\n",
    "    print(\"  Mean:\", np.mean(X))\n",
    "    print(\"  Std Dev:\", np.std(X))\n",
    "print_stats(\"Raw Train\", X_train)\n",
    "print_stats(\"Scaled Train\", X_train_scaled)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for Raw Train:\n",
      "  Max: 7959.375\n",
      "  Min: -8463.542\n",
      "  Mean: 35.578327\n",
      "  Std Dev: 354.76443\n",
      "\n",
      "Stats for Scaled Train:\n",
      "  Max: 17.163582\n",
      "  Min: -11.583979\n",
      "  Mean: 1.6705884e-09\n",
      "  Std Dev: 1.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "# Saving features (both scaled and raw), for later experimenting",
   "metadata": {
    "id": "ujVoGFMu7MvT"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T00:36:46.679791Z",
     "start_time": "2025-08-31T00:36:41.064783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save features (generic helper used for both scaled and raw)\n",
    "from pathlib import Path\n",
    "\n",
    "def save_npz(out_dir: Path, split_name: str, X, y, classes):\n",
    "    # ensure output directory exists\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(out_dir / f\"{split_name}.npz\",\n",
    "                        X=X, y=y.astype(np.int64), classes=np.array(classes))\n",
    "\n",
    "# Save SCALED -> ./features_scaled\n",
    "OUT_DIR_SCALED = Path(\"./features_scaled\")\n",
    "\n",
    "save_npz(OUT_DIR_SCALED, \"train\", X_train_scaled, y_train, classes)\n",
    "save_npz(OUT_DIR_SCALED, \"val\",   X_val_scaled,   y_val,   classes)\n",
    "save_npz(OUT_DIR_SCALED, \"test\",  X_test_scaled,  y_test,  classes)\n",
    "\n",
    "print(\"Saved scaled features:\", sorted(p.name for p in OUT_DIR_SCALED.glob(\"*.npz\")))\n",
    "\n",
    "# Save RAW -> ./features_raw\n",
    "OUT_DIR_RAW = Path(\"./features_raw\")\n",
    "\n",
    "save_npz(OUT_DIR_RAW, \"train\", X_train, y_train, classes)\n",
    "save_npz(OUT_DIR_RAW, \"val\",   X_val,   y_val,   classes)\n",
    "save_npz(OUT_DIR_RAW, \"test\",  X_test,  y_test,  classes)\n",
    "\n",
    "print(\"Saved raw features:\", sorted(p.name for p in OUT_DIR_RAW.glob(\"*.npz\")))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaled features: ['test.npz', 'train.npz', 'val.npz']\n",
      "Saved raw features: ['test.npz', 'train.npz', 'val.npz']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading features back (Be careful with paths)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# load train set (scaled)\n",
    "train_data = np.load(\"./features_scaled/train.npz\", allow_pickle=False)\n",
    "# To load the raw set instead, use:\n",
    "# train_data = np.load(\"./features_raw/train.npz\", allow_pickle=False)\n",
    "\n",
    "X_trainLoaded = train_data[\"X\"]\n",
    "y_trainLoaded = train_data[\"y\"]\n",
    "classesLoaded = train_data[\"classes\"].tolist()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Just checking loaded data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Printing type/shape of loaded features, what float type, and classes\n",
    "print(\"\\nLoaded Train set:\")\n",
    "print(\"X dtype:\", X_trainLoaded.dtype)\n",
    "print(\"y dtype:\", y_trainLoaded.dtype)\n",
    "print(\"Loaded X type:\", type(X_trainLoaded), \"shape:\", X_trainLoaded.shape)\n",
    "print(\"Loaded y type:\", type(y_trainLoaded), \"shape:\", y_trainLoaded.shape)\n",
    "print(\"Loaded classes:\", classesLoaded)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# stats\n",
    "print_stats(\"Loaded Train\", X_trainLoaded)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading scaler back for inference"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "scaler = joblib.load(\"feature_scaler.joblib\")\n",
    "# checking stats of loaded scaler\n",
    "print(\"\\nLoaded scaler mean:\", scaler.mean_)\n",
    "print(\"Loaded scaler scale:\", scaler.scale_)\n",
    "# Now you can scale new data the same way:\n",
    "# X_new_scaled = scaler.transform(X_new)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "outputs": [],
   "execution_count": null
  }
 ]
}
